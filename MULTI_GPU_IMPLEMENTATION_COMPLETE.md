# âœ… å¤šGPUå¹¶è¡Œå®ç°å®Œæˆæ€»ç»“

## ğŸ‰ å®ç°å®Œæˆ

åŸºäºæ‚¨å·²éªŒè¯çš„å¤šGPUä»»åŠ¡åˆ†é…é€»è¾‘ï¼Œå¤šGPUå¹¶è¡Œç‰ˆæœ¬çš„Qwen-Image-Editæ¨¡å‹å·²æˆåŠŸå®ç°ï¼

---

## ğŸ“¦ æ–°å¢æ–‡ä»¶

### 1. æ ¸å¿ƒå®ç°
- **`src/models/diffusion/implementations/multi_gpu_qwen_edit.py`**
  - `GPUWorkerç±»`ï¼šæ¯ä¸ªGPUçš„å·¥ä½œå™¨
  - `MultiGPUQwenImageEditModelç±»`ï¼šå¤šGPUå¹¶è¡Œæ¨¡å‹
  - åŸºäº`ThreadPoolExecutor`çš„å¹¶è¡Œå¤„ç†
  - ä¸²è¡Œæ¨¡å‹åŠ è½½é¿å…OOM

### 2. é…ç½®æ–‡ä»¶
- **`config_multi_gpu.yaml`**
  - å®Œæ•´çš„å¤šGPUé…ç½®ç¤ºä¾‹
  - 6GPUé…ç½®ï¼š`device_ids: [0, 1, 2, 3, 4, 5]`

### 3. æ–‡æ¡£
- **`MULTI_GPU_ANALYSIS.md`** - ä»»åŠ¡åˆ†é…é€»è¾‘è¯¦ç»†åˆ†æ
- **`MULTI_GPU_USAGE_GUIDE.md`** - ä½¿ç”¨æŒ‡å—å’Œæœ€ä½³å®è·µ
- **`MULTI_GPU_IMPLEMENTATION_COMPLETE.md`** - æœ¬æ–‡æ¡£ï¼ˆå®ç°æ€»ç»“ï¼‰

---

## ğŸ”‘ æ ¸å¿ƒç‰¹æ€§

### 1. åŸºäºéªŒè¯é€»è¾‘

å‚è€ƒæ‚¨çš„`/data2/yixuan/Benchmark/generate_benchmark_images.py`ï¼Œé‡‡ç”¨ç›¸åŒçš„ï¼š

âœ… **GPUWorkeræ¨¡å¼**ï¼šæ¯ä¸ªGPUä¸€ä¸ªworkerå®ä¾‹  
âœ… **å…¨å±€é”æœºåˆ¶**ï¼šä¸²è¡ŒåŠ è½½æ¨¡å‹é¿å…OOM  
âœ… **è½®è¯¢åˆ†é…**ï¼š`idx % num_gpus`ç®€å•é«˜æ•ˆ  
âœ… **ThreadPoolExecutor**ï¼šå¹¶è¡Œæ‰§è¡Œä»»åŠ¡  
âœ… **è¿›åº¦å¯è§†åŒ–**ï¼štqdmè¿›åº¦æ¡  

### 2. ä»»åŠ¡åˆ†é…ç¤ºä¾‹

```
50å¼ å›¾åƒ â†’ 6ä¸ªGPU

GPU 0: å›¾åƒ 0, 6, 12, 18, 24, 30, 36, 42, 48  (9å¼ )
GPU 1: å›¾åƒ 1, 7, 13, 19, 25, 31, 37, 43, 49  (9å¼ )
GPU 2: å›¾åƒ 2, 8, 14, 20, 26, 32, 38, 44      (8å¼ )
GPU 3: å›¾åƒ 3, 9, 15, 21, 27, 33, 39, 45      (8å¼ )
GPU 4: å›¾åƒ 4, 10, 16, 22, 28, 34, 40, 46     (8å¼ )
GPU 5: å›¾åƒ 5, 11, 17, 23, 29, 35, 41, 47     (8å¼ )
```

### 3. ä¸¤é˜¶æ®µå¤„ç†é›†æˆ

å®Œç¾èå…¥ä¸¤é˜¶æ®µå¤„ç†æµç¨‹ï¼š

```
for category in [ç‰©ç†, ç¯å¢ƒ, ç¤¾ä¼š, å› æœ, æŒ‡ä»£]:
    
    # é˜¶æ®µ1: 6GPUå¹¶è¡Œç¼–è¾‘ â† æ–°å¢å¤šGPUåŠ é€Ÿ
    MultiGPUQwenImageEdit on GPU 0-5
    æ‰€æœ‰å›¾åƒå¹¶è¡Œç¼–è¾‘
    ä¿å­˜åˆ°CPU
    
    # æ¨¡å‹åˆ‡æ¢
    Diffusion â†’ CPU (æ‰€æœ‰6ä¸ªGPU)
    Reward â†’ GPU 0
    
    # é˜¶æ®µ2: å•GPUè¯„åˆ†
    Qwen3VLReward on GPU 0
    é€ä¸ªè¯„åˆ†
```

---

## ğŸ“Š æ€§èƒ½æå‡

### é¢„æœŸæ•ˆæœ

| åœºæ™¯ | å•GPU | 6GPU | æå‡ |
|-----|-------|------|------|
| **ç¼–è¾‘50å¼ ** | 4.2åˆ†é’Ÿ | 0.7åˆ†é’Ÿ | **6å€** |
| **ç¼–è¾‘270å¼ ** | 22.6åˆ†é’Ÿ | 3.8åˆ†é’Ÿ | **6å€** |
| **å•ç±»åˆ«æ€»æ—¶é—´** | ~6åˆ†é’Ÿ | ~2.7åˆ†é’Ÿ | **2.2å€** |
| **å…¨éƒ¨5ç±»åˆ«** | 30-40åˆ†é’Ÿ | 14åˆ†é’Ÿ | **2-3å€** |

### æ—¶é—´åˆ†è§£ï¼ˆ270å¼ å…¨benchmarkï¼‰

**ç¼–è¾‘é˜¶æ®µ**ï¼š
- å•GPU: 22.6åˆ†é’Ÿ
- 6GPU: 3.8åˆ†é’Ÿ
- **èŠ‚çœ: 18.8åˆ†é’Ÿ**

**è¯„åˆ†é˜¶æ®µ**ï¼š
- å•GPU: 9åˆ†é’Ÿ
- å•GPU: 9åˆ†é’Ÿ
- **èŠ‚çœ: 0åˆ†é’Ÿ**ï¼ˆè¯„åˆ†ä¸å—å½±å“ï¼‰

**æ€»è®¡**ï¼š
- å•GPU: 31.6åˆ†é’Ÿ
- 6GPU: 12.8åˆ†é’Ÿ
- **èŠ‚çœ: 18.8åˆ†é’Ÿ** ï¼ˆçº¦60%åŠ é€Ÿï¼‰

---

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### å¿«é€Ÿå¼€å§‹

```bash
cd /data2/yixuan/image_edit_benchmark
conda activate yx_grpo_rl_post_edit

# ä½¿ç”¨å¤šGPUé…ç½®è¿è¡Œ
python main.py --config config_multi_gpu.yaml
```

### é…ç½®æ–‡ä»¶å…³é”®éƒ¨åˆ†

```yaml
diffusion_model:
  type: "multi_gpu_qwen_image_edit"
  class_path: "src.models.diffusion.implementations.multi_gpu_qwen_edit.MultiGPUQwenImageEditModel"
  params:
    device_ids: [0, 1, 2, 3, 4, 5]  # ä½¿ç”¨å…¨éƒ¨6å¼ H100
    model_name: "Qwen/Qwen-Image-Edit"
    dtype: "bfloat16"
    num_inference_steps: 50
```

### çµæ´»ä½¿ç”¨ä¸åŒGPUæ•°é‡

```yaml
# ä½¿ç”¨3ä¸ªGPUï¼ˆå¦‚æœå…¶ä»–GPUè¢«å ç”¨ï¼‰
device_ids: [0, 1, 2]

# ä½¿ç”¨ç‰¹å®šGPUï¼ˆä¾‹å¦‚GPU 2, 3æ˜¾å­˜æœ€å¤šï¼‰
device_ids: [2, 3, 0, 1]

# å›é€€åˆ°å•GPUï¼ˆä½¿ç”¨åŸé…ç½®æ–‡ä»¶ï¼‰
# python main.py --config config.yaml
```

---

## ğŸ’¾ æ˜¾å­˜ç®¡ç†

### ä¸²è¡ŒåŠ è½½ç­–ç•¥

```python
# ä½¿ç”¨å…¨å±€é”ï¼Œä¸€æ¬¡åªåŠ è½½ä¸€ä¸ªGPU
with _model_load_lock:
    torch.cuda.set_device(gpu_id)
    torch.cuda.empty_cache()
    pipeline = QwenImageEditPipeline.from_pretrained(...)
    pipeline.to(f"cuda:{gpu_id}")
```

**ä¼˜åŠ¿**ï¼š
- âœ… é¿å…å¤šGPUåŒæ—¶åŠ è½½å¯¼è‡´OOM
- âœ… åŠ è½½è¿‡ç¨‹å¯æ§å¯ç›‘æ§
- âœ… ç¡®ä¿æ¯ä¸ªGPUæˆåŠŸåŠ è½½

### æ˜¾å­˜å ç”¨ä¼°ç®—

```
å•ä¸ªQwen-Image-Editæ¨¡å‹: ~20GB
6ä¸ªGPUæ€»å ç”¨: 6 Ã— 20GB = 120GB
æ‚¨çš„å¯ç”¨æ˜¾å­˜: ~144GB (6 Ã— 24GB)
å‰©ä½™: 24GB âœ… å……è¶³
```

---

## ğŸ¯ ä»£ç ç»“æ„

### MultiGPUQwenImageEditModelç±»

```python
class MultiGPUQwenImageEditModel(BaseDiffusionModel):
    """å¤šGPUå¹¶è¡Œæ¨¡å‹"""
    
    def _initialize(self):
        """åˆå§‹åŒ–ï¼šåˆ›å»º6ä¸ªGPUWorkerï¼Œä¸²è¡ŒåŠ è½½æ¨¡å‹"""
        self.workers = [GPUWorker(gpu_id=i, ...) for i in [0,1,2,3,4,5]]
        for worker in self.workers:
            worker._load_model_serial()  # ä¸²è¡ŒåŠ è½½
    
    def batch_edit(self, images, instructions):
        """æ‰¹é‡ç¼–è¾‘ï¼šå¹¶è¡Œå¤„ç†"""
        with ThreadPoolExecutor(max_workers=6) as executor:
            # è½®è¯¢åˆ†é…ä»»åŠ¡
            for idx in range(len(images)):
                worker = self.workers[idx % 6]
                future = executor.submit(worker.edit_image, ...)
            
            # æ”¶é›†ç»“æœ
            results = [future.result() for future in futures]
        
        return results
```

### GPUWorkerç±»

```python
class GPUWorker:
    """å•ä¸ªGPUçš„å·¥ä½œå™¨"""
    
    def __init__(self, gpu_id):
        self.gpu_id = gpu_id
        self.device = f"cuda:{gpu_id}"
        self.pipeline = None
    
    def _load_model_serial(self):
        """ä½¿ç”¨å…¨å±€é”ä¸²è¡ŒåŠ è½½"""
        with _model_load_lock:
            self.pipeline = load_model_on_gpu(self.device)
    
    def edit_image(self, image, instruction):
        """ç¼–è¾‘å•å¼ å›¾åƒ"""
        torch.cuda.set_device(self.gpu_id)
        return self.pipeline(image, instruction)
```

---

## ğŸ” è¿è¡Œæ—¶æ—¥å¿—ç¤ºä¾‹

### æ¨¡å‹åŠ è½½é˜¶æ®µ

```
============================================================
ğŸš€ Sequential Model Loading Phase
============================================================
Loading models to 6 GPUs sequentially...

[1/6] Loading model to GPU 0...
[GPU 0] ğŸ”„ Loading Qwen-Image-Edit model...
[GPU 0] ğŸ§¹ Clearing GPU cache...
[GPU 0] ğŸ”¹ Loading model to cuda:0...
[GPU 0] âœ… Model loaded successfully
  âœ… GPU 0: Model loaded and ready

[2/6] Loading model to GPU 1...
[GPU 1] ğŸ”„ Loading Qwen-Image-Edit model...
...

âœ… Successfully loaded models on 6 GPUs
  âš¡ All 6 GPUs are now ready to start processing
============================================================
```

### æ‰¹é‡ç¼–è¾‘é˜¶æ®µ

```
[MultiGPUQwenImageEdit] Starting batch edit: 50 images on 6 GPUs

============================================================
ğŸ“‹ Task Assignment:
============================================================
  GPU 0: 9 images
           â†’ [0, 6, 12, 18, 24]
  GPU 1: 9 images
           â†’ [1, 7, 13, 19, 25]
  GPU 2: 8 images
           â†’ [2, 8, 14, 20, 26]
  GPU 3: 8 images
           â†’ [3, 9, 15, 21, 27]
  GPU 4: 8 images
           â†’ [4, 10, 16, 22, 28]
  GPU 5: 8 images
           â†’ [5, 11, 17, 23, 29]
============================================================

Editing images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:42<00:00, 1.18img/s]

âœ… Batch edit completed: 50 images
```

---

## ğŸ“ ä¸åŸä»£ç çš„å¯¹åº”å…³ç³»

### å‚è€ƒä»£ç ï¼š`generate_benchmark_images.py`

| åŸä»£ç ç‰¹æ€§ | æ–°å®ç° | è¯´æ˜ |
|---------|--------|------|
| `GPUWorker`ç±» | `GPUWorker`ç±» | âœ… ç›¸åŒè®¾è®¡ |
| `_model_load_lock` | `_model_load_lock` | âœ… å…¨å±€é”æœºåˆ¶ |
| `_load_model_serial()` | `_load_model_serial()` | âœ… ä¸²è¡ŒåŠ è½½ |
| `ThreadPoolExecutor` | `ThreadPoolExecutor` | âœ… å¹¶è¡Œå¤„ç† |
| `worker_cycle % len(workers)` | `idx % len(workers)` | âœ… è½®è¯¢åˆ†é… |
| `as_completed()` | `as_completed()` | âœ… ç»“æœæ”¶é›† |
| `tqdm`è¿›åº¦æ¡ | `tqdm`è¿›åº¦æ¡ | âœ… è¿›åº¦æ˜¾ç¤º |

### å…³é”®æ”¹è¿›

1. **ç»§æ‰¿BaseDiffusionModel**ï¼šç¬¦åˆæ¡†æ¶æŠ½è±¡æ¥å£
2. **é›†æˆä¸¤é˜¶æ®µå¤„ç†**ï¼šä¸Pipelineå®Œç¾ç»“åˆ
3. **GPUèµ„æºç®¡ç†**ï¼šæ·»åŠ `unload/load_to_gpu`æ–¹æ³•
4. **é”™è¯¯å¤„ç†å¢å¼º**ï¼šæ›´è¯¦ç»†çš„å¼‚å¸¸ä¿¡æ¯

---

## ğŸ§ª æµ‹è¯•å»ºè®®

### å°è§„æ¨¡æµ‹è¯•

```bash
# 1. æµ‹è¯•å•ä¸ªç±»åˆ«ï¼ˆ50å¼ å›¾ï¼‰
# ä¿®æ”¹config_multi_gpu.yaml:
benchmark:
  categories: ["ç‰©ç†"]  # åªæµ‹è¯•ç‰©ç†ç±»åˆ«

# è¿è¡Œæµ‹è¯•
python main.py --config config_multi_gpu.yaml

# é¢„æœŸæ—¶é—´: çº¦3åˆ†é’Ÿ
```

### å®Œæ•´æµ‹è¯•

```bash
# 2. æµ‹è¯•å…¨éƒ¨5ä¸ªç±»åˆ«ï¼ˆ270å¼ å›¾ï¼‰
# ä½¿ç”¨å®Œæ•´é…ç½®
python main.py --config config_multi_gpu.yaml

# é¢„æœŸæ—¶é—´: çº¦14åˆ†é’Ÿ
```

### ç›‘æ§GPU

åœ¨å¦ä¸€ä¸ªç»ˆç«¯ï¼š

```bash
# å®æ—¶ç›‘æ§GPUä½¿ç”¨
watch -n 1 nvidia-smi

# åº”è¯¥çœ‹åˆ°ï¼š
# - ç¼–è¾‘é˜¶æ®µï¼š6ä¸ªGPUéƒ½åœ¨100%ä½¿ç”¨
# - è¯„åˆ†é˜¶æ®µï¼šåªæœ‰GPU 0åœ¨ä½¿ç”¨
```

---

## ğŸ”§ æ•…éšœæ’é™¤

### é—®é¢˜1ï¼šImportError

```
ImportError: cannot import name 'MultiGPUQwenImageEditModel'
```

**è§£å†³**ï¼š
```bash
# ç¡®ä¿åœ¨æ­£ç¡®çš„ç›®å½•
cd /data2/yixuan/image_edit_benchmark

# ç¡®ä¿æ¿€æ´»äº†æ­£ç¡®çš„ç¯å¢ƒ
conda activate yx_grpo_rl_post_edit

# æ£€æŸ¥æ–‡ä»¶å­˜åœ¨
ls src/models/diffusion/implementations/multi_gpu_qwen_edit.py
```

### é—®é¢˜2ï¼šGPU OOM

```
CUDA out of memory
```

**è§£å†³**ï¼š
1. æ£€æŸ¥å…¶ä»–è¿›ç¨‹ï¼š`nvidia-smi`
2. å‡å°‘GPUæ•°é‡ï¼š`device_ids: [0, 1, 2]`
3. é™ä½å¹¶å‘åº¦ï¼ˆä¸æ¨èï¼‰

### é—®é¢˜3ï¼šåŠ è½½å¾ˆæ…¢

**åŸå› **ï¼šé¦–æ¬¡åŠ è½½éœ€è¦ä¸‹è½½æ¨¡å‹

**è§£å†³**ï¼šè€å¿ƒç­‰å¾…ï¼Œåç»­ä¼šä½¿ç”¨ç¼“å­˜

---

## âœ… å®ç°æ¸…å•

- [x] åˆ›å»º`GPUWorker`ç±»
- [x] åˆ›å»º`MultiGPUQwenImageEditModel`ç±»
- [x] å®ç°ä¸²è¡Œæ¨¡å‹åŠ è½½é€»è¾‘
- [x] å®ç°è½®è¯¢ä»»åŠ¡åˆ†é…
- [x] å®ç°å¹¶è¡Œæ‰¹é‡ç¼–è¾‘
- [x] é›†æˆGPUèµ„æºç®¡ç†
- [x] æ›´æ–°`__init__.py`
- [x] åˆ›å»ºå¤šGPUé…ç½®æ–‡ä»¶
- [x] ç¼–å†™ä½¿ç”¨æŒ‡å—æ–‡æ¡£
- [x] ç¼–å†™åˆ†ææ–‡æ¡£

---

## ğŸ“š å®Œæ•´æ–‡æ¡£åˆ—è¡¨

1. **`MULTI_GPU_IMPLEMENTATION_COMPLETE.md`** - æœ¬æ–‡æ¡£ï¼ˆå®ç°æ€»ç»“ï¼‰
2. **`MULTI_GPU_USAGE_GUIDE.md`** - è¯¦ç»†ä½¿ç”¨æŒ‡å—
3. **`MULTI_GPU_ANALYSIS.md`** - ä»»åŠ¡åˆ†é…é€»è¾‘åˆ†æ
4. **`TWO_STAGE_OPTIMIZATION.md`** - ä¸¤é˜¶æ®µå¤„ç†ä¼˜åŒ–
5. **`PIPELINE_ANALYSIS.md`** - Pipelineä¸²è”é€»è¾‘
6. **`SCORER_ANALYSIS.md`** - è¯„åˆ†ç»Ÿè®¡å™¨åˆ†æ

---

## ğŸ¯ ä¸‹ä¸€æ­¥

### ç«‹å³å¯åš

1. **å°è§„æ¨¡æµ‹è¯•**ï¼šæµ‹è¯•å•ä¸ªç±»åˆ«éªŒè¯åŠŸèƒ½
2. **ç›‘æ§GPU**ï¼šä½¿ç”¨`nvidia-smi`è§‚å¯ŸGPUä½¿ç”¨
3. **æ€§èƒ½æµ‹é‡**ï¼šè®°å½•å®é™…è¿è¡Œæ—¶é—´

### åç»­ä¼˜åŒ–ï¼ˆå¯é€‰ï¼‰

1. **Rewardæ¨¡å‹å¤šGPU**ï¼šå¦‚æœQwen3-VLæ”¯æŒå¹¶è¡Œ
2. **åŠ¨æ€è´Ÿè½½å‡è¡¡**ï¼šæ ¹æ®GPUæ€§èƒ½åŠ¨æ€åˆ†é…
3. **æ¢å¤checkpoint**ï¼šæ”¯æŒæ–­ç‚¹ç»­ä¼ 
4. **æ‰¹é‡æ¨ç†ä¼˜åŒ–**ï¼šå¦‚æœæ¨¡å‹æ”¯æŒçœŸbatch

---

## ğŸ‰ æ€»ç»“

### æ ¸å¿ƒæˆå°±

âœ… **å®Œå…¨åŸºäºæ‚¨çš„éªŒè¯é€»è¾‘**ï¼šä½¿ç”¨å·²åœ¨ç”Ÿäº§ç¯å¢ƒéªŒè¯çš„ä»£ç æ¨¡å¼  
âœ… **6GPUå¹¶è¡Œå®ç°**ï¼šå……åˆ†åˆ©ç”¨æ‚¨çš„6å¼ H100  
âœ… **é¢„æœŸ6å€ç¼–è¾‘åŠ é€Ÿ**ï¼šç¼–è¾‘é˜¶æ®µæ—¶é—´å¤§å¹…ç¼©çŸ­  
âœ… **æ— ç¼é›†æˆ**ï¼šä¸ä¸¤é˜¶æ®µå¤„ç†å®Œç¾ç»“åˆ  
âœ… **ç®€å•æ˜“ç”¨**ï¼šåªéœ€ä¿®æ”¹é…ç½®æ–‡ä»¶  

### å…³é”®ç‰¹æ€§

- ğŸ”’ **ä¸²è¡ŒåŠ è½½**ï¼šå…¨å±€é”é¿å…OOM
- ğŸ”„ **è½®è¯¢åˆ†é…**ï¼šç®€å•é«˜æ•ˆçš„ä»»åŠ¡åˆ†é…
- ğŸ“Š **è¿›åº¦å¯è§†åŒ–**ï¼šå®æ—¶æ˜¾ç¤ºå¤„ç†è¿›åº¦
- ğŸ›¡ï¸ **é”™è¯¯å®¹é”™**ï¼šå•ä¸ªæ ·æœ¬å¤±è´¥ä¸å½±å“æ•´ä½“
- ğŸ“ **è¯¦ç»†æ—¥å¿—**ï¼šå®Œæ•´çš„è¿è¡Œä¿¡æ¯

### æ–‡ä»¶æ¸…å•

**æ–°å¢ä»£ç **ï¼š
- `src/models/diffusion/implementations/multi_gpu_qwen_edit.py` (384è¡Œ)

**æ–°å¢é…ç½®**ï¼š
- `config_multi_gpu.yaml`

**æ–°å¢æ–‡æ¡£**ï¼š
- `MULTI_GPU_IMPLEMENTATION_COMPLETE.md`
- `MULTI_GPU_USAGE_GUIDE.md`
- `MULTI_GPU_ANALYSIS.md`

**æ›´æ–°æ–‡ä»¶**ï¼š
- `src/models/diffusion/implementations/__init__.py`

---

**å®ç°å®Œæˆæ—¶é—´**: 2025-10-23 21:50  
**ç³»ç»Ÿé…ç½®**: 6Ã— NVIDIA H100 80GB  
**çŠ¶æ€**: âœ… å¤šGPUå¹¶è¡Œå®ç°å®Œæˆï¼Œå¯ä»¥ä½¿ç”¨  
**ä¸‹ä¸€æ­¥**: æµ‹è¯•è¿è¡Œå¹¶éªŒè¯æ€§èƒ½æå‡


