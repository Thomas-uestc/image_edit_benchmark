# ğŸ› è°ƒè¯•ä¿®å¤æ—¥å¿—

## é—®é¢˜: é…ç½®æ–‡ä»¶å­—æ®µåé”™è¯¯

### é—®é¢˜æè¿°

```
ValueError: Missing 'user_prompt_template' for category: ç‰©ç†
```

ä½¿ç”¨ `config_full_multi_gpu.yaml` å¯åŠ¨æ—¶æŠ¥é”™ã€‚

### åŸå› åˆ†æ

`PromptManager` æœŸæœ›çš„å­—æ®µåæ˜¯ `user_prompt_template`ï¼Œä½† `config_full_multi_gpu.yaml` ä¸­ä½¿ç”¨çš„æ˜¯ `user_prompt`ã€‚

**PromptManager æœŸæœ›çš„æ ¼å¼**ï¼š
```yaml
prompts:
  ç‰©ç†:
    system_prompt: |
      ...
    user_prompt_template: |  # âœ… æ­£ç¡®çš„å­—æ®µå
      ...
```

**config_full_multi_gpu.yaml ä¸­çš„é”™è¯¯æ ¼å¼**ï¼š
```yaml
prompts:
  ç‰©ç†:
    system_prompt: |
      ...
    user_prompt: |  # âŒ é”™è¯¯çš„å­—æ®µå
      ...
```

### è§£å†³æ–¹æ¡ˆ

ä¿®æ”¹ `config_full_multi_gpu.yaml`ï¼Œå°†æ‰€æœ‰5ä¸ªç±»åˆ«çš„ `user_prompt:` æ”¹ä¸º `user_prompt_template:`ï¼š

```yaml
# ä¿®æ”¹å‰ âŒ
user_prompt: |
  Please evaluate...

# ä¿®æ”¹å âœ…
user_prompt_template: |
  Please evaluate...
```

### æ–‡ä»¶ä¿®æ”¹

- âœ… `config_full_multi_gpu.yaml`
  - ç‰©ç†ç»´åº¦ï¼š`user_prompt` â†’ `user_prompt_template`
  - ç¯å¢ƒç»´åº¦ï¼š`user_prompt` â†’ `user_prompt_template`
  - ç¤¾ä¼šç»´åº¦ï¼š`user_prompt` â†’ `user_prompt_template`
  - å› æœç»´åº¦ï¼š`user_prompt` â†’ `user_prompt_template`
  - æŒ‡ä»£ç»´åº¦ï¼š`user_prompt` â†’ `user_prompt_template`

### çŠ¶æ€

âœ… **å·²ä¿®å¤** - 2025-10-23

---

## é—®é¢˜: å¤šGPUæ¨¡å‹å¯¼å…¥è·¯å¾„é”™è¯¯

### é—®é¢˜æè¿°

```
ModuleNotFoundError: No module named 'src.models.reward.base'
File ".../qwen3_vl_multi_gpu_subprocess.py", line 17, in <module>
    from ..base import BaseRewardModel
```

### åŸå› åˆ†æ

åœ¨åˆ›å»º `qwen3_vl_multi_gpu_subprocess.py` æ—¶ï¼Œå¯¼å…¥è·¯å¾„å†™é”™äº†ï¼š

**é”™è¯¯çš„å¯¼å…¥**ï¼š
```python
from ..base import BaseRewardModel  # base æ¨¡å—ä¸å­˜åœ¨
```

**æ­£ç¡®çš„å¯¼å…¥**ï¼š
```python
from ..base_reward import BaseRewardModel  # æ­£ç¡®çš„æ¨¡å—å
```

### è§£å†³æ–¹æ¡ˆ

ä¿®æ”¹ `src/models/reward/implementations/qwen3_vl_multi_gpu_subprocess.py`ï¼š

```python
# ä¿®æ”¹å‰ âŒ
from ..base import BaseRewardModel
from ....utils.logger import setup_logger

# ä¿®æ”¹å âœ…
from ..base_reward import BaseRewardModel
from ....utils import setup_logger
```

### æ–‡ä»¶ä¿®æ”¹

- âœ… `src/models/reward/implementations/qwen3_vl_multi_gpu_subprocess.py`
  - ä¿®æ­£å¯¼å…¥è·¯å¾„

### çŠ¶æ€

âœ… **å·²ä¿®å¤** - 2025-10-23

---

## é—®é¢˜: Reward Model åˆ†æ•°æå–å¤±è´¥å’Œè¾“å‡ºå»¶è¿Ÿ

### é—®é¢˜æè¿°

**é—®é¢˜1ï¼šåˆ†æ•°æå–å¤±è´¥**
```
[Warning] Could not extract score from: '8.500'
[Sample 0] Score: 5.00 | Response: 8.500...
[Warning] Could not extract score from: '9.500'
[Sample 1] Score: 5.00 | Response: 9.500...
...
Average score: 5.000  â† æ‰€æœ‰åˆ†æ•°éƒ½æ˜¯é»˜è®¤å€¼
```

**é—®é¢˜2ï¼šè¾“å‡ºä¸æ˜¯å®æ—¶çš„**
- æ‰€æœ‰è¾“å‡ºåœ¨è¯„åˆ†å®Œæˆåä¸€æ¬¡æ€§æ˜¾ç¤º
- æ— æ³•å®æ—¶çœ‹åˆ°è¯„åˆ†è¿›åº¦

### åŸå› åˆ†æ

#### é—®é¢˜1ï¼šåˆ†æ•°æå–å¤±è´¥

**Promptè¦æ±‚æ¨¡å‹è¾“å‡º**ï¼š
```
Format for Output:
You must output the score in the following format:
Score: X.XXX
```

**æ¨¡å‹å®é™…è¾“å‡º**ï¼š
```
8.500  ï¼ˆçº¯æ•°å­—ï¼Œæ²¡æœ‰ "Score:" å‰ç¼€ï¼‰
```

**åŸå§‹æ­£åˆ™è¡¨è¾¾å¼**ï¼š
```python
patterns = [
    r'Score:\s*(\d+\.?\d*)',  # åªèƒ½åŒ¹é… "Score: 8.500"
    r'è¯„åˆ†[:ï¼š]\s*(\d+\.?\d*)',
    # ...
]
```

âŒ **æ— æ³•åŒ¹é…çº¯æ•°å­—**ï¼Œå¯¼è‡´æ‰€æœ‰åˆ†æ•°ä½¿ç”¨é»˜è®¤å€¼ 5.0

#### é—®é¢˜2ï¼šè¾“å‡ºå»¶è¿Ÿ

- Pythonçš„ `print()` é»˜è®¤ä½¿ç”¨ç¼“å†²
- åœ¨subprocessä¸­ï¼Œè¾“å‡ºè¢«å®Œå…¨ç¼“å†²
- åªæœ‰ç¼“å†²åŒºæ»¡æˆ–ç¨‹åºé€€å‡ºæ—¶æ‰ä¼šflush

### è§£å†³æ–¹æ¡ˆ

#### ä¿®å¤1ï¼šä¼˜åŒ–åˆ†æ•°æå–

**æ·»åŠ å¤šç§åŒ¹é…æ¨¡å¼**ï¼š

```python
def extract_score(self, response: str) -> float:
    response = response.strip()
    
    patterns = [
        # æ ‡å‡†æ ¼å¼
        r'Score:\s*(\d+\.?\d*)',
        # çº¯æ•°å­—æ ¼å¼ â­ NEW
        r'^\s*(\d+\.\d+)\s*$',  # 8.500
        r'^\s*(\d+)\s*$',        # 8
        # ä¸­æ–‡æ ¼å¼
        r'è¯„åˆ†[:ï¼š]\s*(\d+\.?\d*)',
        # å®½æ¾åŒ¹é…
        r'(\d+\.\d+)',
        r'(\d+)',
    ]
    
    for pattern in patterns:
        match = re.search(pattern, response, re.IGNORECASE)
        if match:
            try:
                score = float(match.group(1))
                if 0 <= score <= 10:
                    return score
            except (ValueError, IndexError):
                continue
    
    return 5.0
```

#### ä¿®å¤2ï¼šæ·»åŠ å®æ—¶è¾“å‡º

**åœ¨æ‰€æœ‰printè¯­å¥ä¸­æ·»åŠ  `flush=True`**ï¼š

```python
# ä¿®æ”¹å‰
print(f"[Sample {idx}] Score: {score:.2f}", file=sys.stderr)

# ä¿®æ”¹å
print(f"[Sample {idx}] Score: {score:.2f}", file=sys.stderr, flush=True)
```

### æ•ˆæœå¯¹æ¯”

**ä¿®å¤å‰**ï¼š
```
[Warning] Could not extract score from: '8.500'
[Sample 0] Score: 5.00  â† é”™è¯¯
ï¼ˆç­‰å¾…4åˆ†é’Ÿåä¸€æ¬¡æ€§è¾“å‡ºæ‰€æœ‰å†…å®¹ï¼‰
Average score: 5.000  â† é”™è¯¯
```

**ä¿®å¤å**ï¼š
```
ï¼ˆå®æ—¶æ˜¾ç¤ºï¼‰
[Sample 0] Score: 8.50 | Response: 8.500...  â† æ­£ç¡®
[Sample 1] Score: 9.10 | Response: 9.100...  â† æ­£ç¡®
[Sample 2] Score: 7.20 | Response: 7.200...  â† æ­£ç¡®
...
Average score: 8.267  â† æ­£ç¡®
```

### æ–‡ä»¶ä¿®æ”¹

- âœ… `src/models/reward/qwen3_vl_standalone.py`
  - ä¼˜åŒ– `extract_score()` æ–¹æ³•ï¼ˆæ·»åŠ çº¯æ•°å­—åŒ¹é…ï¼‰
  - æ‰€æœ‰printè¯­å¥æ·»åŠ  `flush=True`
- âœ… `REWARD_MODEL_FIXES.md` - è¯¦ç»†ä¿®å¤æ–‡æ¡£

### çŠ¶æ€

âœ… **å·²ä¿®å¤** - 2025-10-23

---

## è§£å†³æ–¹æ¡ˆ: å¤šGPUè¯„åˆ†åŠ é€Ÿ

### é—®é¢˜æè¿°

**ç”¨æˆ·è§‚å¯Ÿ**ï¼šè¯„åˆ†é˜¶æ®µåªæœ‰GPU 0åœ¨å·¥ä½œï¼ˆ63%åˆ©ç”¨ç‡ï¼‰ï¼Œå…¶ä»–5ä¸ªGPUå®Œå…¨ç©ºé—²ï¼ˆ0%åˆ©ç”¨ç‡ï¼‰

**nvidia-smiè¾“å‡º**ï¼š
```
GPU 0: 63% Util, 219W    â† å·¥ä½œä¸­
GPU 1: 0% Util,  192W    â† ç©ºé—²
GPU 2: 0% Util,  199W    â† ç©ºé—²
GPU 3: 0% Util,  227W    â† ç©ºé—²
GPU 4: 0% Util,  202W    â† ç©ºé—²
GPU 5: 0% Util,  190W    â† ç©ºé—²
```

### åŸå› åˆ†æ

è¿™**ä¸æ˜¯bug**ï¼Œè€Œæ˜¯transformers `device_map="auto"` çš„é¢„æœŸè¡Œä¸ºï¼š

1. **Qwen3-VL-30B** åœ¨ bfloat16 ä¸‹çº¦ **60GB**
2. **H100 80GB** å•å¡å°±èƒ½è£…ä¸‹æ•´ä¸ªæ¨¡å‹
3. `device_map="auto"` çš„ç­–ç•¥ï¼š**å¦‚æœå•å¡èƒ½è£…ä¸‹ï¼Œå°±åªç”¨å•å¡**ï¼ˆé¿å…GPUé—´é€šä¿¡å¼€é”€ï¼‰
4. **Batch inference ä¸ç­‰äºå¤šGPU**ï¼Œå®ƒåªæ˜¯åœ¨å•ä¸ªæ¨¡å‹ä¸Šå¹¶è¡Œå¤„ç†å¤šä¸ªæ ·æœ¬

### è§£å†³æ–¹æ¡ˆï¼šæ•°æ®å¹¶è¡Œï¼ˆæ¨èï¼‰

**åŸç†**ï¼šæ¯ä¸ªGPUè¿è¡Œä¸€ä¸ªç‹¬ç«‹çš„æ¨¡å‹å®ä¾‹ï¼Œå¤„ç†ä¸åŒçš„å›¾åƒ

```
GPU 0: æ¨¡å‹A â†’ images 0, 6, 12, ...
GPU 1: æ¨¡å‹B â†’ images 1, 7, 13, ...
GPU 2: æ¨¡å‹C â†’ images 2, 8, 14, ...
GPU 3: æ¨¡å‹D â†’ images 3, 9, 15, ...
GPU 4: æ¨¡å‹E â†’ images 4, 10, 16, ...
GPU 5: æ¨¡å‹F â†’ images 5, 11, 17, ...
```

**å®ç°**ï¼šæ–°å¢ `Qwen3VLMultiGPUSubprocessRewardModel`

```python
class Qwen3VLMultiGPUSubprocessRewardModel(BaseRewardModel):
    def __init__(self, config):
        self.device_ids = config.get("device_ids", [0,1,2,3,4,5])
        self.num_gpus = len(self.device_ids)
    
    def batch_score(self, edited_images, ...):
        # 1. ä»»åŠ¡åˆ†é…
        gpu_tasks = [[] for _ in range(self.num_gpus)]
        for i, task in enumerate(all_tasks):
            gpu_idx = i % self.num_gpus
            gpu_tasks[gpu_idx].append(task)
        
        # 2. å¹¶è¡Œæ‰§è¡Œï¼ˆæ¯ä¸ªGPUè¿è¡Œç‹¬ç«‹å­è¿›ç¨‹ï¼‰
        with ThreadPoolExecutor(max_workers=self.num_gpus) as executor:
            futures = []
            for gpu_id, tasks in zip(self.device_ids, gpu_tasks):
                future = executor.submit(
                    self._call_subprocess_single_gpu,
                    tasks,
                    gpu_id  # æŒ‡å®šGPU: cuda:0, cuda:1, ...
                )
                futures.append(future)
            
            # 3. æ”¶é›†ç»“æœ
            for future in futures:
                scores.extend(future.result())
```

**é…ç½®æ–‡ä»¶**ï¼š`config_full_multi_gpu.yaml`

```yaml
reward_model:
  type: "qwen3_vl_multi_gpu_subprocess"
  class_path: "src.models.reward.implementations.qwen3_vl_multi_gpu_subprocess.Qwen3VLMultiGPUSubprocessRewardModel"
  params:
    device_ids: [0, 1, 2, 3, 4, 5]  # 6ä¸ªGPU
    batch_size: 2  # æ¯ä¸ªGPUçš„batch size
    conda_env: "yx_qwen3"
```

### æ€§èƒ½æå‡

**å•GPUè¯„åˆ†ï¼ˆå½“å‰ï¼‰**ï¼š
- GPUåˆ©ç”¨ï¼šä»…GPU 0
- è¯„åˆ†æ—¶é—´ï¼š~4åˆ†é’Ÿ/10å¼ å›¾
- å®Œæ•´benchmarkï¼ˆ900å¼ ï¼‰ï¼š~6å°æ—¶

**å¤šGPUè¯„åˆ†ï¼ˆæ–°æ–¹æ¡ˆï¼‰**ï¼š
- GPUåˆ©ç”¨ï¼šæ‰€æœ‰6ä¸ªGPU
- è¯„åˆ†æ—¶é—´ï¼š~40ç§’/10å¼ å›¾ï¼ˆ**6å€åŠ é€Ÿ**ï¼‰
- å®Œæ•´benchmarkï¼š~1å°æ—¶ï¼ˆ**èŠ‚çœ5å°æ—¶**ï¼‰

### æ˜¾å­˜ä½¿ç”¨

- **å•GPUæ¨¡å¼**ï¼š65GB (ä»…GPU 0)
- **å¤šGPUæ¨¡å¼**ï¼š372GB (åˆ†å¸ƒåœ¨6ä¸ªGPUï¼Œæ¯ä¸ª62GB)
- **æ€»å¯ç”¨**ï¼š480GB (6Ã—80GB)
- **åˆ©ç”¨ç‡**ï¼š77.5%

### æ–‡ä»¶ä¿®æ”¹

1. âœ… `src/models/reward/implementations/qwen3_vl_multi_gpu_subprocess.py` - æ–°å¢
2. âœ… `src/models/reward/implementations/__init__.py` - æ›´æ–°å¯¼å…¥
3. âœ… `config_full_multi_gpu.yaml` - æ–°é…ç½®æ–‡ä»¶
4. âœ… `MULTI_GPU_SCORING_SOLUTION.md` - è¯¦ç»†æ–‡æ¡£
5. âœ… `QUICK_TEST_MULTI_GPU_SCORING.sh` - æµ‹è¯•è„šæœ¬

### ä½¿ç”¨æ–¹æ³•

```bash
# è¿è¡Œå¤šGPUè¯„åˆ†
conda activate yx_grpo_rl_post_edit
cd /data2/yixuan/image_edit_benchmark
python main.py --config config_full_multi_gpu.yaml

# æˆ–ä½¿ç”¨æµ‹è¯•è„šæœ¬
./QUICK_TEST_MULTI_GPU_SCORING.sh

# ç›‘æ§GPUï¼ˆå¦ä¸€ä¸ªç»ˆç«¯ï¼‰
watch -n 1 nvidia-smi
```

### çŠ¶æ€

âœ… **å·²å®ç°** - 2025-10-23

---

## ä¼˜åŒ–: è¿›åº¦æ˜¾ç¤ºå¢å¼º

### é—®é¢˜æè¿°

**ç”¨æˆ·éœ€æ±‚**ï¼š
1. **ç¼–è¾‘é˜¶æ®µ**ï¼šå¸Œæœ›çœ‹åˆ°å„ä¸ªGPU Workerçš„å»å™ªè¿›åº¦æ¡ï¼Œäº†è§£æ¯ä¸ªGPUçš„å®æ—¶çŠ¶æ€
2. **è¯„åˆ†é˜¶æ®µ**ï¼šå¸Œæœ›çœ‹åˆ°æ¯ä¸ªæ ·æœ¬çš„è¯¦ç»†åˆ†æ•°å’Œæ¨¡å‹å“åº”ï¼Œè€Œä¸ä»…ä»…æ˜¯å¼€å§‹å’Œç»“æŸ

### è§£å†³æ–¹æ¡ˆ

#### 1. ç¼–è¾‘é˜¶æ®µï¼šæ·»åŠ å»å™ªè¿›åº¦æ¡

**ä¿®æ”¹æ–‡ä»¶**ï¼š`src/models/diffusion/implementations/multi_gpu_qwen_edit.py`

**å®ç°**ï¼š
- ä¸º `edit_image()` æ·»åŠ  `show_progress` å‚æ•°ï¼ˆé»˜è®¤Trueï¼‰
- ä½¿ç”¨ diffusers pipeline çš„ `callback_on_step_end` é’©å­
- ä¸ºæ¯ä¸ªGPUåˆ›å»ºç‹¬ç«‹çš„ tqdm è¿›åº¦æ¡ï¼ˆä½¿ç”¨ `position` å‚æ•°ï¼‰

```python
if show_progress:
    pbar = tqdm(total=num_steps, 
               desc=f"[GPU {self.gpu_id}] Denoising", 
               unit="step", 
               leave=False,
               position=self.gpu_id)
    
    def callback(pipe, step_index, timestep, callback_kwargs):
        pbar.update(1)
        return callback_kwargs
    
    inputs["callback_on_step_end"] = callback
```

**æ•ˆæœ**ï¼š
```
[GPU 0] Denoising: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:17<00:00]
[GPU 1] Denoising:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:15<00:02]
[GPU 2] Denoising:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 28/30 [00:16<00:01]
...
[SYNC] Editing images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:53<00:00]
```

#### 2. è¯„åˆ†é˜¶æ®µï¼šæ˜¾ç¤ºè¯¦ç»†åˆ†æ•°

**ä¿®æ”¹æ–‡ä»¶1**ï¼š`src/models/reward/qwen3_vl_standalone.py`

**å®ç°**ï¼š
- æ·»åŠ è¯„åˆ†å¼€å§‹ä¿¡æ¯ï¼ˆæ€»æ•°ã€batch sizeã€batchæ•°ï¼‰
- ä¸ºæ¯ä¸ªæ ·æœ¬æ‰“å°è¯¦ç»†ä¿¡æ¯ï¼ˆåˆ†æ•°ã€æ¨¡å‹å“åº”ï¼‰
- ä¸ºæ¯ä¸ªbatchæ‰“å°ç»Ÿè®¡ï¼ˆå¹³å‡åˆ†ï¼‰
- æ·»åŠ æœ€ç»ˆæ€»ç»“ï¼ˆæ€»æ•°ã€å¹³å‡ã€æœ€é«˜ã€æœ€ä½åˆ†ï¼‰

```python
# æ ·æœ¬çº§åˆ«
print(f"  [Sample {idx:3d}] Score: {score:.2f} | Response: {text[:80]}...")

# æ‰¹æ¬¡çº§åˆ«
print(f"[Batch {batch_num}] Images {start}-{end} done, avg_score={avg:.3f}")

# æ€»ç»“çº§åˆ«
print(f"[Qwen3-VL Scoring] Completed!")
print(f"  Total images: {n}")
print(f"  Average score: {avg:.3f}")
print(f"  Min/Max score: {min_score:.3f} / {max_score:.3f}")
```

**ä¿®æ”¹æ–‡ä»¶2**ï¼š`src/models/reward/implementations/qwen3_vl_subprocess.py`

**å®ç°**ï¼š
- ä½¿ç”¨ `subprocess.Popen` æ›¿ä»£ `subprocess.run`
- å®æ—¶è¯»å–å¹¶æ‰“å° stderr è¾“å‡º
- ç¡®ä¿ç”¨æˆ·èƒ½çœ‹åˆ° standalone è„šæœ¬çš„è¯¦ç»†è¾“å‡º

```python
process = subprocess.Popen(cmd, stdout=PIPE, stderr=PIPE, text=True)

# å®æ—¶æ‰“å°stderr
while True:
    line = process.stderr.readline()
    if line:
        print(line.rstrip())
    elif process.poll() is not None:
        break
```

### æ€§èƒ½å½±å“

- **ç¼–è¾‘é˜¶æ®µ**ï¼š< 1% é¢å¤–å¼€é”€ï¼ˆä»…è¿›åº¦æ¡æ›´æ–°ï¼‰
- **è¯„åˆ†é˜¶æ®µ**ï¼š< 0.5% é¢å¤–å¼€é”€ï¼ˆæ‰“å°è¾“å‡ºï¼‰
- **ç”¨æˆ·ä½“éªŒ**ï¼šå¤§å¹…æå‡ âœ¨

### æ–‡ä»¶ä¿®æ”¹

1. `src/models/diffusion/implementations/multi_gpu_qwen_edit.py`
2. `src/models/reward/qwen3_vl_standalone.py`
3. `src/models/reward/implementations/qwen3_vl_subprocess.py`
4. æ–°å¢æ–‡æ¡£ï¼š`PROGRESS_DISPLAY_OPTIMIZATION.md`
5. æ–°å¢æµ‹è¯•è„šæœ¬ï¼š`QUICK_TEST_PROGRESS.sh`

### çŠ¶æ€

âœ… **å·²å®Œæˆå¹¶ä¼˜åŒ–** - 2025-10-23

---

## ä¼˜åŒ–: æ¨¡å‹å¸è½½å¹¶è¡ŒåŒ–

### é—®é¢˜æè¿°

**ç”¨æˆ·å‘ç°**ï¼šåŠ è½½æ¨¡å‹æ—¶ä¸²è¡Œå¾ˆå¿…è¦ï¼ˆé¿å…OOMï¼‰ï¼Œä½†å¸è½½æ—¶ä¹Ÿä¸²è¡Œå°±æ²¡å¿…è¦äº†

```python
# åŸå®ç°ï¼šä¸²è¡Œå¸è½½
def unload_from_gpu(self):
    for worker in self.workers:
        worker.unload_from_gpu()  # ä¸€ä¸ªä¸€ä¸ªå¸è½½ï¼Œæ…¢
```

### åŸå› åˆ†æ

**åŠ è½½éœ€è¦ä¸²è¡Œ**ï¼š
- é¦–æ¬¡åŠ è½½æ¨¡å‹éœ€è¦åˆ†é…å¤§é‡GPUæ˜¾å­˜
- å¤šGPUåŒæ—¶åŠ è½½ä¼šç«äº‰æ˜¾å­˜èµ„æº â†’ OOMé£é™©
- âœ… ä¸²è¡ŒåŠ è½½å®‰å…¨ç¨³å®š

**å¸è½½å¯ä»¥å¹¶è¡Œ**ï¼š
- åªæ˜¯é‡Šæ”¾æ˜¾å­˜ï¼Œä¸åˆ†é…èµ„æº
- æ¯ä¸ªGPUç‹¬ç«‹æ“ä½œï¼Œæ— èµ„æºç«äº‰
- âœ… å¹¶è¡Œå¸è½½æ›´å¿«ï¼Œ6ä¸ªGPUå¯æé€Ÿ6å€

**é‡æ–°åŠ è½½ä¹Ÿå¯ä»¥å¹¶è¡Œ**ï¼š
- æ¨¡å‹å·²åœ¨å†…å­˜ä¸­ï¼Œåªæ˜¯ä»CPUç§»å›GPU
- ä¸åƒé¦–æ¬¡åŠ è½½é‚£æ ·è€—èµ„æº
- âœ… å¹¶è¡ŒåŠ è½½æ›´å¿«ï¼ˆä½†ä¿ç•™ä¸²è¡Œé€‰é¡¹ä»¥é˜²ä¸‡ä¸€ï¼‰

### è§£å†³æ–¹æ¡ˆ

**1. å¹¶è¡Œå¸è½½ï¼ˆé»˜è®¤ï¼‰**

```python
def unload_from_gpu(self):
    """å¹¶è¡Œå¸è½½æ‰€æœ‰GPUä¸Šçš„æ¨¡å‹"""
    print(f"Unloading models from {len(self.workers)} GPUs (parallel)...")
    
    from concurrent.futures import ThreadPoolExecutor, as_completed
    with ThreadPoolExecutor(max_workers=len(self.workers)) as executor:
        futures = [executor.submit(worker.unload_from_gpu) for worker in self.workers]
        for future in as_completed(futures):
            try:
                future.result()
            except Exception as e:
                print(f"âš ï¸ Error during unload: {e}")
    
    print(f"All models unloaded")
```

**2. çµæ´»åŠ è½½ï¼ˆæ”¯æŒä¸²è¡Œ/å¹¶è¡Œï¼‰**

```python
def load_to_gpu(self, parallel: bool = True):
    """å°†æ¨¡å‹ä»CPUåŠ è½½å›GPU"""
    if parallel:
        # å¹¶è¡ŒåŠ è½½ï¼ˆé»˜è®¤ï¼Œæ¨èï¼‰
        with ThreadPoolExecutor(max_workers=len(self.workers)) as executor:
            futures = [executor.submit(worker.load_to_gpu) for worker in self.workers]
            # ... ç­‰å¾…å®Œæˆ
    else:
        # ä¸²è¡ŒåŠ è½½ï¼ˆä¿å®ˆæ¨¡å¼ï¼‰
        for worker in self.workers:
            worker.load_to_gpu()
```

### æ€§èƒ½æå‡

- **6å¼ GPU**ï¼šå¸è½½æ—¶é—´ä» ~12ç§’ â†’ ~2ç§’ï¼ˆ**6å€æå‡**ï¼‰
- **æ¯ä¸ªç±»åˆ«**ï¼šèŠ‚çœçº¦ 10ç§’
- **å®Œæ•´benchmark**ï¼š5ç±» Ã— 10ç§’ = **èŠ‚çœ50ç§’**

### æ–‡ä»¶ä¿®æ”¹

- `src/models/diffusion/implementations/multi_gpu_qwen_edit.py`
  - `unload_from_gpu()`: æ”¹ä¸ºå¹¶è¡Œå¸è½½
  - `load_to_gpu(parallel=True)`: æ”¯æŒå¹¶è¡Œ/ä¸²è¡ŒåŠ è½½
- æ–°å¢æ–‡æ¡£ï¼š`UNLOAD_OPTIMIZATION.md`

### çŠ¶æ€

âœ… **å·²ä¿®å¤å¹¶ä¼˜åŒ–** - 2025-10-23

---

## é—®é¢˜1: æŠ½è±¡æ–¹æ³•æœªå®ç°

### é”™è¯¯ä¿¡æ¯

```
TypeError: Can't instantiate abstract class Qwen3VLSubprocessRewardModel 
with abstract method _initialize
```

### åŸå› åˆ†æ

`Qwen3VLSubprocessRewardModel` ç»§æ‰¿è‡ª `BaseRewardModel`ï¼Œè€Œ `BaseRewardModel` ç»§æ‰¿è‡ª `BaseModel`ã€‚

`BaseModel` å®šä¹‰äº†ä¸€ä¸ªæŠ½è±¡æ–¹æ³• `_initialize()`ï¼Œæ‰€æœ‰å­ç±»å¿…é¡»å®ç°ï¼š

```python
class BaseModel(ABC):
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self._initialize()  # è°ƒç”¨æŠ½è±¡æ–¹æ³•
    
    @abstractmethod
    def _initialize(self):
        """åˆå§‹åŒ–æ¨¡å‹ï¼ˆç”±å­ç±»å®ç°ï¼‰"""
        pass
```

### è§£å†³æ–¹æ¡ˆ

åœ¨ `Qwen3VLSubprocessRewardModel` ä¸­æ·»åŠ  `_initialize()` æ–¹æ³•å®ç°ï¼š

```python
class Qwen3VLSubprocessRewardModel(BaseRewardModel):
    def __init__(self, config: Dict[str, Any]):
        self.logger = setup_logger(self.__class__.__name__)
        
        # å…ˆåˆå§‹åŒ–å®ä¾‹å±æ€§
        self.model_name = config.get("model_name", "...")
        self.device = config.get("device", "auto")
        # ... å…¶ä»–å±æ€§
        
        # ç„¶åè°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–ï¼ˆä¼šè°ƒç”¨_initializeï¼‰
        super().__init__(config)
    
    def _initialize(self):
        """åˆå§‹åŒ–æ¨¡å‹ï¼ˆå®ç°BaseModelçš„æŠ½è±¡æ–¹æ³•ï¼‰"""
        # æ£€æµ‹è„šæœ¬è·¯å¾„
        if self.script_path is None:
            current_dir = Path(__file__).parent.parent
            self.script_path = current_dir / "qwen3_vl_standalone.py"
        else:
            self.script_path = Path(self.script_path)
        
        # éªŒè¯è„šæœ¬å­˜åœ¨
        if not self.script_path.exists():
            raise FileNotFoundError(f"Standalone script not found: {self.script_path}")
        
        # è¾“å‡ºåˆå§‹åŒ–ä¿¡æ¯
        self.logger.info(f"Initialized Qwen3-VL Subprocess Reward Model")
        self.logger.info(f"  Model: {self.model_name}")
        self.logger.info(f"  Script: {self.script_path}")
        if self.conda_env:
            self.logger.info(f"  Conda Env: {self.conda_env}")
```

### å…³é”®ç‚¹

1. **å±æ€§åˆå§‹åŒ–é¡ºåº**ï¼š
   - å…ˆåˆå§‹åŒ– `self.logger` å’Œå…¶ä»–å®ä¾‹å±æ€§
   - å†è°ƒç”¨ `super().__init__(config)`
   - è¿™æ · `_initialize()` æ–¹æ³•å¯ä»¥è®¿é—®è¿™äº›å±æ€§

2. **æ–¹æ³•å®ç°**ï¼š
   - å¿…é¡»å®ç° `_initialize()` æ–¹æ³•
   - è¯¥æ–¹æ³•ä¸æ¥å—å‚æ•°ï¼ˆé™¤äº†selfï¼‰
   - å¯ä»¥ä½¿ç”¨ `self.config` è®¿é—®é…ç½®

### çŠ¶æ€

âœ… **å·²ä¿®å¤** - `src/models/reward/implementations/qwen3_vl_subprocess.py`

---

## æµ‹è¯•éªŒè¯

```bash
# é‡æ–°è¿è¡Œæµ‹è¯•
conda activate yx_grpo_rl_post_edit
cd /data2/yixuan/image_edit_benchmark

# æµ‹è¯•å­è¿›ç¨‹æ–¹æ¡ˆ
python main.py --config config_multi_gpu_subprocess.yaml --categories ç‰©ç†
```

---

## å…¶ä»–å¯èƒ½çš„é—®é¢˜

### é—®é¢˜ï¼šæ‰¾ä¸åˆ°standaloneè„šæœ¬

**é”™è¯¯**ï¼š
```
FileNotFoundError: Standalone script not found: .../qwen3_vl_standalone.py
```

**è§£å†³**ï¼š
```bash
# ç¡®è®¤æ–‡ä»¶å­˜åœ¨
ls -l src/models/reward/qwen3_vl_standalone.py

# å¦‚æœä¸å­˜åœ¨ï¼Œæ–‡ä»¶è·¯å¾„å¯èƒ½æœ‰é—®é¢˜
```

### é—®é¢˜ï¼šcondaç¯å¢ƒä¸å­˜åœ¨

**é”™è¯¯**ï¼š
```
conda: command not found
# æˆ–
Could not find conda environment: qwen3_vl_env
```

**è§£å†³**ï¼š
```bash
# æ–¹æ¡ˆ1ï¼šåˆå§‹åŒ–conda
source ~/miniconda3/etc/profile.d/conda.sh

# æ–¹æ¡ˆ2ï¼šåˆ›å»ºç¯å¢ƒ
bash setup_qwen3_vl_env.sh

# æ–¹æ¡ˆ3ï¼šä½¿ç”¨python_pathä»£æ›¿conda_env
# åœ¨configä¸­ï¼š
reward_model:
  params:
    python_path: "/path/to/python"  # è€Œä¸æ˜¯conda_env
```

---

**ä¿®å¤æ—¶é—´**: 2025-10-23 22:35  
**çŠ¶æ€**: âœ… å·²è§£å†³

---

## é—®é¢˜2: é…ç½®é”®åä¸åŒ¹é…

### é”™è¯¯ä¿¡æ¯

```
KeyError: 'results_dir'
```

### åŸå› åˆ†æ

Pipelineä»£ç ä¸­ä½¿ç”¨çš„é”®åæ˜¯ `results_dir`ï¼š

```python
self.reporter = Reporter(
    output_dir=self.config["evaluation"]["results_dir"],  # âŒ ä½¿ç”¨results_dir
    logger=self.logger
)
```

ä½†é…ç½®æ–‡ä»¶ä¸­ä½¿ç”¨çš„é”®åæ˜¯ `output_dir`ï¼š

```yaml
evaluation:
  output_dir: "outputs"  # âœ… é…ç½®ä¸­æ˜¯output_dir
```

### è§£å†³æ–¹æ¡ˆ

ä¿®æ”¹Pipelineä»£ç ï¼Œå…¼å®¹ä¸¤ç§é”®åï¼Œå¹¶æä¾›é»˜è®¤å€¼ï¼š

```python
# è·å–è¾“å‡ºç›®å½•ï¼ˆå…¼å®¹output_dirå’Œresults_dirä¸¤ç§é…ç½®ï¼‰
eval_config = self.config.get("evaluation", {})
output_dir = eval_config.get("output_dir") or eval_config.get("results_dir", "outputs")

self.reporter = Reporter(
    output_dir=output_dir,
    logger=self.logger
)
```

### å…³é”®ç‚¹

1. **å‘åå…¼å®¹**ï¼šåŒæ—¶æ”¯æŒ `output_dir` å’Œ `results_dir` ä¸¤ç§é”®å
2. **é»˜è®¤å€¼**ï¼šå¦‚æœéƒ½ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤å€¼ `"outputs"`
3. **ä¼˜å…ˆçº§**ï¼šä¼˜å…ˆä½¿ç”¨ `output_dir`ï¼Œå…¶æ¬¡ `results_dir`ï¼Œæœ€åé»˜è®¤å€¼

### çŠ¶æ€

âœ… **å·²ä¿®å¤** - `src/pipeline.py`

---

**æœ€åæ›´æ–°**: 2025-10-23 22:37  
**çŠ¶æ€**: âœ… ä¸¤ä¸ªé—®é¢˜å·²è§£å†³

---

## é—®é¢˜3: å¤šGPUæœªå¹¶è¡Œå·¥ä½œ

### ç—‡çŠ¶

ä»nvidia-smiç›‘æ§çœ‹åˆ°ï¼š
- GPU 0: 100%åˆ©ç”¨ç‡ï¼Œ692WåŠŸç‡ âœ…
- GPU 1-5: 0%åˆ©ç”¨ç‡ï¼Œä½åŠŸç‡ âŒ

è™½ç„¶æ¨¡å‹å·²åŠ è½½åˆ°æ‰€æœ‰6ä¸ªGPUï¼Œä½†å®é™…æ‰§è¡Œæ—¶åªç”¨äº†GPU 0ã€‚

### åŸå› åˆ†æ

Pipelineä¸­ç¼–è¾‘é˜¶æ®µä½¿ç”¨çš„æ˜¯**é€å¼ å¤„ç†**ï¼š

```python
# âŒ é”™è¯¯çš„æ–¹å¼
for pair in pbar_edit:
    edited_image = self.diffusion_model.edit_image(  # å•å¼ å¤„ç†
        original_image=pair.original_image,
        edit_instruction=pair.edit_instruction
    )
```

è€Œ`MultiGPUQwenImageEditModel.edit_image()`çš„å®ç°æ˜¯ï¼š

```python
def edit_image(self, original_image, edit_instruction, **kwargs):
    """å•å¼ å›¾åƒä½¿ç”¨ç¬¬ä¸€ä¸ªGPU"""
    return self.workers[0].edit_image(...)  # â† åªç”¨GPU 0ï¼
```

**é—®é¢˜æ ¹æº**ï¼šæ²¡æœ‰ä½¿ç”¨`batch_edit()`æ–¹æ³•ï¼Œè€Œ`batch_edit()`æ‰ä¼šå¤šGPUå¹¶è¡Œã€‚

### è§£å†³æ–¹æ¡ˆ

ä¿®æ”¹Pipelineï¼Œä½¿ç”¨æ‰¹é‡å¤„ç†ï¼š

```python
# âœ… æ­£ç¡®çš„æ–¹å¼

# 1. å‡†å¤‡æ‰€æœ‰æ•°æ®
original_images = [pair.original_image for pair in category_data.data_pairs]
edit_instructions = [pair.edit_instruction for pair in category_data.data_pairs]

# 2. ä½¿ç”¨batch_editè¿›è¡Œå¤šGPUå¹¶è¡Œç¼–è¾‘
if hasattr(self.diffusion_model, 'batch_edit'):
    # å¤šGPUå¹¶è¡Œ
    edited_images = self.diffusion_model.batch_edit(
        images=original_images,
        instructions=edit_instructions
    )
else:
    # å›é€€åˆ°å•GPUé€å¼ å¤„ç†
    edited_images = [
        self.diffusion_model.edit_image(img, inst)
        for img, inst in zip(original_images, edit_instructions)
    ]

# 3. åˆ†é…ç»“æœ
for pair, edited_image in zip(category_data.data_pairs, edited_images):
    pair.edited_image = edited_image
```

### å…³é”®æ”¹è¿›

1. **æ‰¹é‡æ”¶é›†**ï¼šä¸€æ¬¡æ€§æ”¶é›†æ‰€æœ‰å›¾åƒå’ŒæŒ‡ä»¤
2. **æ‰¹é‡å¤„ç†**ï¼šè°ƒç”¨`batch_edit()`è€Œä¸æ˜¯å¾ªç¯è°ƒç”¨`edit_image()`
3. **å¤šGPUå¹¶è¡Œ**ï¼š`batch_edit()`å†…éƒ¨ä½¿ç”¨ThreadPoolExecutor + è½®è¯¢åˆ†é…
4. **é”™è¯¯å¤„ç†**ï¼šå¦‚æœbatch_editå¤±è´¥ï¼Œè‡ªåŠ¨å›é€€åˆ°é€å¼ å¤„ç†

### é¢„æœŸæ•ˆæœ

ä¿®å¤åï¼Œæ‰€æœ‰6ä¸ªGPUåº”è¯¥éƒ½ä¼šæ˜¾ç¤ºé«˜åˆ©ç”¨ç‡ï¼š

```
GPU 0: 100%åˆ©ç”¨ç‡ âœ…
GPU 1: 100%åˆ©ç”¨ç‡ âœ…
GPU 2: 100%åˆ©ç”¨ç‡ âœ…
GPU 3: 100%åˆ©ç”¨ç‡ âœ…
GPU 4: 100%åˆ©ç”¨ç‡ âœ…
GPU 5: 100%åˆ©ç”¨ç‡ âœ…
```

### çŠ¶æ€

âœ… **å·²ä¿®å¤** - `src/pipeline.py`

---

**æœ€åæ›´æ–°**: 2025-10-23 22:42  
**çŠ¶æ€**: âœ… ä¸‰ä¸ªé—®é¢˜å·²è§£å†³

---

## é—®é¢˜4: Qwen3-VL messagesæ ¼å¼é”™è¯¯

### é”™è¯¯ä¿¡æ¯

```
TypeError: string indices must be integers, not 'str'
```

å®Œæ•´tracebackæŒ‡å‘ï¼š
```python
visuals = [content for content in message["content"] if content["type"] in ["image", "video"]]
                                                        ~~~~~~~^^^^^^^^
```

### åŸå› åˆ†æ

åœ¨`qwen3_vl_standalone.py`ä¸­æ„å»ºmessagesæ—¶ï¼Œ`system`è§’è‰²çš„`content`æ˜¯**å­—ç¬¦ä¸²**ï¼š

```python
# âŒ é”™è¯¯æ ¼å¼
messages = [
    {"role": "system", "content": system_prompt},  # contentæ˜¯å­—ç¬¦ä¸²
    {
        "role": "user",
        "content": [
            {"type": "image", "image": image},
            {"type": "text", "text": user_prompt}
        ]
    }
]
```

ä½†Qwen3-VLçš„`apply_chat_template`æœŸæœ›**æ‰€æœ‰è§’è‰²çš„contentéƒ½æ˜¯åˆ—è¡¨æ ¼å¼**ï¼š

```python
# âœ… æ­£ç¡®æ ¼å¼
messages = [
    {
        "role": "system",
        "content": [{"type": "text", "text": system_prompt}]  # åˆ—è¡¨æ ¼å¼
    },
    {
        "role": "user",
        "content": [
            {"type": "image", "image": image},
            {"type": "text", "text": user_prompt}
        ]
    }
]
```

### è§£å†³æ–¹æ¡ˆ

ä¿®æ”¹ä¸¤ä¸ªåœ°æ–¹çš„messagesæ„å»ºï¼š

1. **score_singleæ–¹æ³•**ï¼ˆå•å¼ è¯„åˆ†ï¼‰
2. **score_batchæ–¹æ³•**ï¼ˆæ‰¹é‡è¯„åˆ†ï¼‰

ç»Ÿä¸€æ ¼å¼ä¸ºï¼š
```python
{
    "role": "system",
    "content": [{"type": "text", "text": system_prompt}]
}
```

### å…³é”®ç‚¹

1. **Qwen3-VLè¦æ±‚**ï¼šæ‰€æœ‰è§’è‰²çš„contentå¿…é¡»æ˜¯åˆ—è¡¨æ ¼å¼
2. **å³ä½¿çº¯æ–‡æœ¬**ï¼šä¹Ÿè¦ç”¨`[{"type": "text", "text": "..."}]`æ ¼å¼
3. **å¤šæ¨¡æ€æ¶ˆæ¯**ï¼šå¯ä»¥æ··åˆæ–‡æœ¬å’Œå›¾åƒï¼š
   ```python
   "content": [
       {"type": "text", "text": "..."},
       {"type": "image", "image": ...},
       {"type": "text", "text": "..."}
   ]
   ```

### çŠ¶æ€

âœ… **å·²ä¿®å¤** - `src/models/reward/qwen3_vl_standalone.py`

---

**æœ€åæ›´æ–°**: 2025-10-23 22:45  
**çŠ¶æ€**: âœ… å››ä¸ªé—®é¢˜å·²è§£å†³

