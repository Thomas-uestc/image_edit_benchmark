# ğŸ”§ å­è¿›ç¨‹æ–¹æ¡ˆè®¾ç½®æŒ‡å— - è§£å†³ç¯å¢ƒä¾èµ–å†²çª

## ğŸ“‹ é—®é¢˜èƒŒæ™¯

**åœºæ™¯**ï¼šQwen-Image-Edit å’Œ Qwen3-VL éœ€è¦ä¸åŒçš„ä¾èµ–ç‰ˆæœ¬ï¼Œæ— æ³•åœ¨åŒä¸€ç¯å¢ƒä¸­å…±å­˜ã€‚

**ç¤ºä¾‹å†²çª**ï¼š
- Qwen-Image-Edit éœ€è¦ `transformers==4.38.0`
- Qwen3-VL éœ€è¦ `transformers==4.45.0`

**è§£å†³æ–¹æ¡ˆ**ï¼šä½¿ç”¨ä¸¤ä¸ªç‹¬ç«‹çš„è™šæ‹Ÿç¯å¢ƒï¼Œé€šè¿‡å­è¿›ç¨‹è°ƒç”¨ã€‚

---

## ğŸ¯ æ¶æ„è®¾è®¡

```
ä¸»ç¯å¢ƒ (yx_grpo_rl_post_edit)
â”œâ”€ Qwen-Image-Edit (æ‰©æ•£æ¨¡å‹)
â”œâ”€ Pipelineé€»è¾‘
â””â”€ é€šè¿‡subprocessè°ƒç”¨ â”€â”€â”€â”€â”€â”
                           â”‚
                           â†“
                    Qwen3-VLç¯å¢ƒ (qwen3_vl_env)
                    â”œâ”€ Qwen3-VL-30B
                    â”œâ”€ qwen3_vl_standalone.py
                    â””â”€ è¿”å›è¯„åˆ†ç»“æœ
```

---

## ğŸ“¦ Step 1: åˆ›å»ºQwen3-VLç‹¬ç«‹ç¯å¢ƒ

### 1.1 åˆ›å»ºæ–°çš„Condaç¯å¢ƒ

```bash
# åˆ›å»ºPython 3.10ç¯å¢ƒ
conda create -n qwen3_vl_env python=3.10 -y

# æ¿€æ´»ç¯å¢ƒ
conda activate qwen3_vl_env
```

### 1.2 å®‰è£…Qwen3-VLä¾èµ–

```bash
# å®‰è£…PyTorch (æ ¹æ®æ‚¨çš„CUDAç‰ˆæœ¬)
# CUDA 11.8
conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia -y

# æˆ– CUDA 12.1
# conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia -y

# å®‰è£…transformers (æœ€æ–°ç‰ˆï¼Œæ”¯æŒQwen3-VL)
pip install transformers>=4.45.0

# å®‰è£…å…¶ä»–ä¾èµ–
pip install pillow accelerate

# éªŒè¯å®‰è£…
python -c "from transformers import AutoModelForImageTextToText; print('âœ… Qwen3-VL dependencies OK')"
```

### 1.3 æµ‹è¯•Qwen3-VLç¯å¢ƒ

```bash
# ä»åœ¨qwen3_vl_envç¯å¢ƒä¸­
cd /data2/yixuan/image_edit_benchmark

# æµ‹è¯•standaloneè„šæœ¬
python src/models/reward/qwen3_vl_standalone.py --help

# åº”è¯¥çœ‹åˆ°å¸®åŠ©ä¿¡æ¯
```

---

## ğŸ”§ Step 2: é…ç½®ä¸»ç¯å¢ƒ

### 2.1 ç¡®è®¤ä¸»ç¯å¢ƒ

```bash
# è¿”å›ä¸»ç¯å¢ƒ
conda activate yx_grpo_rl_post_edit

# éªŒè¯Qwen-Image-Editå¯ç”¨
python -c "from diffusers import DiffusionPipeline; print('âœ… Qwen-Image-Edit OK')"
```

### 2.2 æ£€æŸ¥é¡¹ç›®æ–‡ä»¶

```bash
cd /data2/yixuan/image_edit_benchmark

# ç¡®è®¤standaloneè„šæœ¬å­˜åœ¨
ls -lh src/models/reward/qwen3_vl_standalone.py

# ç¡®è®¤subprocesså®ç°å­˜åœ¨
ls -lh src/models/reward/implementations/qwen3_vl_subprocess.py

# ç¡®è®¤é…ç½®æ–‡ä»¶å­˜åœ¨
ls -lh config_multi_gpu_subprocess.yaml
```

---

## âš™ï¸ Step 3: é…ç½®æ–‡ä»¶è®¾ç½®

### 3.1 ç¼–è¾‘é…ç½®æ–‡ä»¶

```bash
vim config_multi_gpu_subprocess.yaml
# æˆ–
nano config_multi_gpu_subprocess.yaml
```

### 3.2 å…³é”®é…ç½®é¡¹

æ‰¾åˆ° `reward_model` éƒ¨åˆ†ï¼Œä¿®æ”¹ä»¥ä¸‹å‚æ•°ï¼š

```yaml
reward_model:
  type: "qwen3_vl_subprocess"  # â­ ä½¿ç”¨å­è¿›ç¨‹ç‰ˆæœ¬
  class_path: "src.models.reward.implementations.qwen3_vl_subprocess.Qwen3VLSubprocessRewardModel"
  params:
    model_name: "Qwen/Qwen3-VL-30B-Instruct"
    
    # â­ é‡è¦ï¼šæŒ‡å®šQwen3-VLç¯å¢ƒ
    # æ–¹å¼1ï¼šä½¿ç”¨condaç¯å¢ƒåï¼ˆæ¨èï¼‰
    conda_env: "qwen3_vl_env"  # ä¿®æ”¹ä¸ºæ‚¨çš„ç¯å¢ƒå
    
    # æ–¹å¼2ï¼šä½¿ç”¨Pythonè·¯å¾„ï¼ˆå¦‚æœä¸ç”¨condaï¼‰
    # python_path: "/home/username/miniconda3/envs/qwen3_vl_env/bin/python"
```

### 3.3 è·å–Pythonè·¯å¾„ï¼ˆå¦‚æœéœ€è¦ï¼‰

å¦‚æœé€‰æ‹©æ–¹å¼2ï¼ˆä½¿ç”¨Pythonè·¯å¾„ï¼‰ï¼š

```bash
# æ¿€æ´»Qwen3-VLç¯å¢ƒ
conda activate qwen3_vl_env

# è·å–Pythonè·¯å¾„
which python
# è¾“å‡ºä¾‹å¦‚ï¼š/home/username/miniconda3/envs/qwen3_vl_env/bin/python

# å¤åˆ¶è¿™ä¸ªè·¯å¾„åˆ°é…ç½®æ–‡ä»¶çš„ python_path
```

---

## ğŸ§ª Step 4: æµ‹è¯•å­è¿›ç¨‹æ–¹æ¡ˆ

### 4.1 å¿«é€Ÿæµ‹è¯•

```bash
# ç¡®ä¿åœ¨ä¸»ç¯å¢ƒ
conda activate yx_grpo_rl_post_edit
cd /data2/yixuan/image_edit_benchmark

# åªæµ‹è¯•ä¸€ä¸ªç±»åˆ«ï¼ˆçº¦1-2åˆ†é’Ÿï¼‰
python main.py --config config_multi_gpu_subprocess.yaml --categories ç‰©ç†
```

### 4.2 æŸ¥çœ‹æ—¥å¿—

```bash
# æŸ¥çœ‹æ—¥å¿—è¾“å‡º
tail -f outputs/logs/benchmark_*.log

# åº”è¯¥çœ‹åˆ°ç±»ä¼¼è¾“å‡ºï¼š
# [Qwen3VLSubprocessRewardModel] Calling subprocess: conda run -n qwen3_vl_env python...
# [Qwen3VL-Standalone] Loading model: Qwen/Qwen3-VL-30B-Instruct
# [Qwen3VL-Standalone] Model loaded on device: cuda
# [Qwen3VL-Standalone] Batch scoring 50 images with batch_size=4
# [Qwen3VLSubprocessRewardModel] Subprocess completed in 45.23s
```

### 4.3 éªŒè¯ç»“æœ

```bash
# æŸ¥çœ‹ç”Ÿæˆçš„æŠ¥å‘Š
cat outputs/evaluation_report_*.md

# æ£€æŸ¥åˆ†æ•°æ˜¯å¦åˆç†ï¼ˆåº”è¯¥åœ¨1.0-10.0ä¹‹é—´ï¼‰
```

---

## ğŸš€ Step 5: å®Œæ•´è¿è¡Œ

å¦‚æœæµ‹è¯•é€šè¿‡ï¼Œè¿è¡Œå®Œæ•´è¯„æµ‹ï¼š

```bash
# è¿è¡Œæ‰€æœ‰ç±»åˆ«ï¼ˆçº¦5-10åˆ†é’Ÿï¼‰
python main.py --config config_multi_gpu_subprocess.yaml
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### æ–¹æ¡ˆå¯¹æ¯”

| æ–¹æ¡ˆ | ç¯å¢ƒæ•°é‡ | è®¾ç½®å¤æ‚åº¦ | è¿è¡Œé€Ÿåº¦ | ç¨³å®šæ€§ |
|-----|---------|-----------|---------|--------|
| **å•ç¯å¢ƒ** | 1 | ç®€å• | å¿« | âš ï¸ ä¾èµ–å†²çª |
| **å­è¿›ç¨‹ï¼ˆæœ¬æ–¹æ¡ˆï¼‰** | 2 | ä¸­ç­‰ | ç•¥æ…¢ | âœ… ç¨³å®š |
| **Docker** | 1+å®¹å™¨ | å¤æ‚ | ä¸­ç­‰ | âœ… ç¨³å®š |

### æ€§èƒ½å¼€é”€

```
å­è¿›ç¨‹æ–¹æ¡ˆçš„é¢å¤–å¼€é”€ï¼š
1. å¯åŠ¨å­è¿›ç¨‹: æ¯æ‰¹æ¬¡çº¦0.5ç§’
2. æ•°æ®ä¼ é€’ï¼ˆJSON + base64ï¼‰: æ¯æ‰¹æ¬¡çº¦1ç§’
3. æ¨¡å‹åŠ è½½ï¼ˆä»…é¦–æ¬¡ï¼‰: çº¦30ç§’

æ€»ä½“å½±å“ï¼š
- ç¼–è¾‘é˜¶æ®µï¼šæ— å½±å“ï¼ˆåœ¨ä¸»ç¯å¢ƒï¼‰
- è¯„åˆ†é˜¶æ®µï¼šå¢åŠ çº¦10-15%æ—¶é—´
- æ€»æ—¶é—´ï¼šä»5åˆ†é’Ÿå¢åŠ åˆ°çº¦5.5-6åˆ†é’Ÿ
```

---

## ğŸ” è°ƒè¯•æŒ‡å—

### é—®é¢˜1ï¼šæ‰¾ä¸åˆ°condaç¯å¢ƒ

**é”™è¯¯**ï¼š
```
[ERROR] conda: command not found
```

**è§£å†³**ï¼š
```bash
# åˆå§‹åŒ–conda
source ~/miniconda3/etc/profile.d/conda.sh
# æˆ–
source ~/anaconda3/etc/profile.d/conda.sh

# å†æ¬¡å°è¯•
python main.py --config config_multi_gpu_subprocess.yaml
```

### é—®é¢˜2ï¼šå­è¿›ç¨‹è¶…æ—¶

**é”™è¯¯**ï¼š
```
[ERROR] Subprocess timeout after 600s
```

**è§£å†³**ï¼š
```yaml
# å¢åŠ è¶…æ—¶æ—¶é—´ï¼ˆåœ¨ä»£ç ä¸­ï¼Œæˆ–ç­‰å¾…ä¿®å¤ï¼‰
# ä¸´æ—¶æ–¹æ¡ˆï¼šå‡å°‘batch_size
reward_model:
  params:
    batch_size: 2  # ä»4é™åˆ°2
```

### é—®é¢˜3ï¼šæ¨¡å‹åŠ è½½å¤±è´¥

**é”™è¯¯**ï¼š
```
[ERROR] Model not found: Qwen/Qwen3-VL-30B-Instruct
```

**è§£å†³**ï¼š
```yaml
# ä½¿ç”¨ç»å¯¹è·¯å¾„
reward_model:
  params:
    model_name: "/absolute/path/to/Qwen3-VL-30B-Instruct"
```

### é—®é¢˜4ï¼šæ˜¾å­˜ä¸è¶³

**é”™è¯¯**ï¼š
```
[ERROR] CUDA out of memory
```

**è§£å†³**ï¼š
```yaml
# å‡å°‘batch_size
reward_model:
  params:
    batch_size: 2  # æˆ– 1

# æˆ–æŒ‡å®šç‰¹å®šGPU
reward_model:
  params:
    device: "cuda:5"  # ä½¿ç”¨ç©ºé—²çš„GPU
```

---

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. ç¯å¢ƒéš”ç¦»ç­–ç•¥

```bash
# ä¸»ç¯å¢ƒï¼šç”¨äºå›¾åƒç¼–è¾‘å’ŒPipeline
yx_grpo_rl_post_edit/
â”œâ”€ Qwen-Image-Edit
â”œâ”€ diffusers
â””â”€ å…¶ä»–Pipelineä¾èµ–

# è¯„åˆ†ç¯å¢ƒï¼šä»…ç”¨äºQwen3-VL
qwen3_vl_env/
â”œâ”€ Qwen3-VL-30B
â”œâ”€ transformers (æœ€æ–°)
â””â”€ æœ€å°ä¾èµ–
```

### 2. èµ„æºåˆ†é…å»ºè®®

```yaml
# ç¼–è¾‘é˜¶æ®µä½¿ç”¨GPU 0-4
diffusion_model:
  params:
    device_ids: [0, 1, 2, 3, 4]

# è¯„åˆ†é˜¶æ®µä½¿ç”¨GPU 5
reward_model:
  params:
    device: "cuda:5"
```

### 3. ç›‘æ§å­è¿›ç¨‹

```bash
# ç»ˆç«¯1ï¼šè¿è¡Œä¸»ç¨‹åº
python main.py --config config_multi_gpu_subprocess.yaml

# ç»ˆç«¯2ï¼šç›‘æ§GPU
watch -n 1 nvidia-smi

# ç»ˆç«¯3ï¼šç›‘æ§è¿›ç¨‹
watch -n 1 "ps aux | grep qwen3_vl_standalone"
```

---

## ğŸ“š æ–‡ä»¶æ¸…å•

### æ–°å¢æ–‡ä»¶

```
src/models/reward/
â”œâ”€â”€ qwen3_vl_standalone.py          # â­ ç‹¬ç«‹è¯„åˆ†è„šæœ¬
â””â”€â”€ implementations/
    â””â”€â”€ qwen3_vl_subprocess.py      # â­ å­è¿›ç¨‹Reward Model

config_multi_gpu_subprocess.yaml     # â­ å­è¿›ç¨‹é…ç½®æ–‡ä»¶
SUBPROCESS_SETUP_GUIDE.md            # â­ æœ¬æ–‡æ¡£
```

### ä¿®æ”¹æ–‡ä»¶

```
src/models/reward/implementations/__init__.py  # æ·»åŠ äº†å¯¼å…¥
```

---

## ğŸ¯ éªŒè¯æ¸…å•

è¿è¡Œå‰ç¡®è®¤ï¼š

- [ ] Qwen3-VLç¯å¢ƒå·²åˆ›å»ºï¼š`conda env list | grep qwen3_vl_env`
- [ ] Qwen3-VLä¾èµ–å·²å®‰è£…ï¼š`conda activate qwen3_vl_env && python -c "from transformers import AutoModelForImageTextToText"`
- [ ] standaloneè„šæœ¬å¯æ‰§è¡Œï¼š`python src/models/reward/qwen3_vl_standalone.py --help`
- [ ] é…ç½®æ–‡ä»¶å·²ä¿®æ”¹ï¼š`grep "conda_env" config_multi_gpu_subprocess.yaml`
- [ ] ä¸»ç¯å¢ƒå¯ç”¨ï¼š`conda activate yx_grpo_rl_post_edit && python -c "from diffusers import DiffusionPipeline"`

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

ä¸€é”®è®¾ç½®è„šæœ¬ï¼š

```bash
#!/bin/bash
# setup_qwen3_vl_env.sh

# 1. åˆ›å»ºç¯å¢ƒ
echo "Creating qwen3_vl_env..."
conda create -n qwen3_vl_env python=3.10 -y

# 2. å®‰è£…ä¾èµ–
echo "Installing dependencies..."
conda activate qwen3_vl_env
conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia -y
pip install transformers>=4.45.0 pillow accelerate

# 3. æµ‹è¯•
echo "Testing installation..."
python -c "from transformers import AutoModelForImageTextToText; print('âœ… Setup complete!')"

echo ""
echo "âœ… Qwen3-VL environment is ready!"
echo "Next steps:"
echo "  1. Edit config_multi_gpu_subprocess.yaml"
echo "  2. Set conda_env: qwen3_vl_env"
echo "  3. Run: python main.py --config config_multi_gpu_subprocess.yaml"
```

ä½¿ç”¨æ–¹æ³•ï¼š

```bash
chmod +x setup_qwen3_vl_env.sh
bash setup_qwen3_vl_env.sh
```

---

## ğŸ“ å¸¸è§é—®é¢˜

### Q1: ä¸ºä»€ä¹ˆä¸ç”¨venvè€Œç”¨condaï¼Ÿ

**A**: Condaæ›´å¥½åœ°å¤„ç†CUDAå’ŒPyTorchä¾èµ–ï¼Œä¸”å‘½ä»¤æ›´ç®€æ´ï¼ˆ`conda run -n env_name`ï¼‰ã€‚

### Q2: å¯ä»¥ç”¨Dockerä»£æ›¿å—ï¼Ÿ

**A**: å¯ä»¥ï¼Œä½†è®¾ç½®æ›´å¤æ‚ã€‚å­è¿›ç¨‹æ–¹æ¡ˆæ›´è½»é‡çº§ã€‚

### Q3: æ€§èƒ½æŸå¤±å¤šå°‘ï¼Ÿ

**A**: çº¦10-15%ï¼Œä¸»è¦åœ¨æ•°æ®ä¼ é€’ä¸Šã€‚å¯¹äºå¤§è§„æ¨¡è¯„æµ‹å¯æ¥å—ã€‚

### Q4: å¯ä»¥åœ¨Windowsä¸Šè¿è¡Œå—ï¼Ÿ

**A**: å¯ä»¥ï¼Œä½†éœ€è¦ä¿®æ”¹subprocessè°ƒç”¨æ–¹å¼ï¼ˆä¸ç”¨conda runï¼‰ã€‚

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2025-10-23  
**çŠ¶æ€**: âœ… æµ‹è¯•é€šè¿‡ï¼Œç”Ÿäº§å¯ç”¨

ğŸ‰ **ç¯å¢ƒéš”ç¦»æ–¹æ¡ˆå·²å°±ç»ªï¼Œè§£å†³ä¾èµ–å†²çªï¼** ğŸš€

