# ğŸ“‹ å‘½ä»¤å‚è€ƒé€ŸæŸ¥è¡¨

## ğŸš€ åŸºç¡€å‘½ä»¤

### 1ï¸âƒ£ å®Œæ•´è¿è¡Œï¼ˆæ¨èï¼‰

```bash
# æ¿€æ´»ç¯å¢ƒ
conda activate yx_grpo_rl_post_edit

# è¿›å…¥ç›®å½•
cd /data2/yixuan/image_edit_benchmark

# è¿è¡Œï¼ˆä½¿ç”¨æ‰€æœ‰ä¼˜åŒ–ï¼š6GPUå¹¶è¡Œ + æ‰¹æ¬¡åŒæ­¥ + Batch Inferenceï¼‰
python main.py --config config_multi_gpu.yaml
```

**é¢„æœŸæ—¶é—´**: çº¦5åˆ†é’Ÿï¼ˆ270å¼ å›¾åƒï¼‰

---

### 2ï¸âƒ£ å¿«é€Ÿæµ‹è¯•

```bash
# åªè¿è¡Œç‰©ç†ç±»åˆ«ï¼ˆ50å¼ å›¾åƒï¼‰
python main.py --config config_multi_gpu.yaml --categories ç‰©ç†
```

**é¢„æœŸæ—¶é—´**: çº¦1åˆ†é’Ÿ

---

### 3ï¸âƒ£ ä½¿ç”¨è„šæœ¬ï¼ˆæœ€ç®€å•ï¼‰

```bash
# ä¸€é”®å¯åŠ¨ï¼ˆäº¤äº’å¼ï¼‰
bash QUICK_START.sh
```

---

## âš™ï¸ é…ç½®æ–‡ä»¶

### å¤šGPUé…ç½®ï¼ˆæ¨èï¼‰

```bash
python main.py --config config_multi_gpu.yaml
```

**ç‰¹æ€§**ï¼š
- âœ… 6ä¸ªGPUå¹¶è¡Œç¼–è¾‘ï¼ˆ6å€åŠ é€Ÿï¼‰
- âœ… æ‰¹æ¬¡åŒæ­¥ï¼ˆGPUä¿æŒåŒæ­¥ï¼‰
- âœ… Batch inferenceè¯„åˆ†ï¼ˆ2.7å€åŠ é€Ÿï¼‰

### å•GPUé…ç½®ï¼ˆæµ‹è¯•ï¼‰

```bash
python main.py --config config.yaml
```

**ç‰¹æ€§**ï¼š
- âš ï¸ å•GPUä¸²è¡Œå¤„ç†
- â±ï¸ è¾ƒæ…¢ï¼ˆçº¦22åˆ†é’Ÿï¼‰

---

## ğŸ¯ å¸¸ç”¨é€‰é¡¹

### æŒ‡å®šç±»åˆ«

```bash
# å•ä¸ªç±»åˆ«
python main.py --config config_multi_gpu.yaml --categories ç‰©ç†

# å¤šä¸ªç±»åˆ«
python main.py --config config_multi_gpu.yaml --categories ç‰©ç† ç¯å¢ƒ ç¤¾ä¼š
```

### æŒ‡å®šè¾“å‡ºç›®å½•

```bash
python main.py --config config_multi_gpu.yaml --output-dir ./my_results
```

### è°ƒè¯•æ¨¡å¼

```bash
python main.py --config config_multi_gpu.yaml --debug
```

### å¹²è·‘æµ‹è¯•ï¼ˆéªŒè¯é…ç½®ï¼‰

```bash
python main.py --config config_multi_gpu.yaml --dry-run
```

---

## ğŸ“Š ç›‘æ§å‘½ä»¤

### å®æ—¶ç›‘æ§GPU

```bash
# ç»ˆç«¯1: è¿è¡Œç¨‹åº
python main.py --config config_multi_gpu.yaml

# ç»ˆç«¯2: ç›‘æ§GPU
watch -n 1 nvidia-smi
```

### æŸ¥çœ‹æ—¥å¿—

```bash
# å®æ—¶æŸ¥çœ‹æ—¥å¿—
tail -f outputs/logs/benchmark_*.log

# æŸ¥çœ‹æœ€æ–°æ—¥å¿—
ls -lt outputs/logs/ | head -n 5
```

### æŸ¥çœ‹è¾“å‡ºæ–‡ä»¶

```bash
# æŸ¥çœ‹ç”Ÿæˆçš„æŠ¥å‘Š
ls -lh outputs/evaluation_report_*.{json,md}

# æŸ¥çœ‹JSONæŠ¥å‘Š
cat outputs/evaluation_report_*.json | jq .

# æŸ¥çœ‹MarkdownæŠ¥å‘Š
cat outputs/evaluation_report_*.md
```

---

## ğŸ”§ é…ç½®ä¿®æ”¹

### ä¸´æ—¶ä¿®æ”¹GPUæ•°é‡

ç¼–è¾‘ `config_multi_gpu.yaml`:

```yaml
diffusion_model:
  params:
    device_ids: [0, 1, 2, 3]  # æ”¹ä¸ºä½¿ç”¨4ä¸ªGPU
```

### ä¸´æ—¶ç¦ç”¨æ‰¹æ¬¡åŒæ­¥

```yaml
diffusion_model:
  params:
    enable_batch_sync: false  # ç¦ç”¨æ‰¹æ¬¡åŒæ­¥
```

### ä¸´æ—¶ä¿®æ”¹Batch Size

```yaml
reward_model:
  params:
    batch_size: 2  # æ”¹ä¸º2ï¼ˆèŠ‚çœæ˜¾å­˜ï¼‰
```

---

## ğŸ› ï¸ æ•…éšœæ’é™¤å‘½ä»¤

### æ£€æŸ¥ç¯å¢ƒ

```bash
# æ£€æŸ¥Condaç¯å¢ƒ
conda env list

# æ£€æŸ¥Pythonç‰ˆæœ¬
python --version

# æ£€æŸ¥PyTorch
python -c "import torch; print(torch.__version__); print(torch.cuda.is_available())"
```

### æ£€æŸ¥GPU

```bash
# ç®€æ´æ˜¾ç¤º
nvidia-smi --query-gpu=index,name,memory.free,memory.total --format=csv

# è¯¦ç»†æ˜¾ç¤º
nvidia-smi
```

### æ£€æŸ¥æ•°æ®æ–‡ä»¶

```bash
# æ£€æŸ¥æ–‡ä»¶å­˜åœ¨
ls -lh /data2/yixuan/Benchmark/version_2_50_pair/version_2_with_imagesb64.json

# æ£€æŸ¥æ–‡ä»¶å†…å®¹
python -c "import json; data=json.load(open('/data2/yixuan/Benchmark/version_2_50_pair/version_2_with_imagesb64.json')); print(f'Total pairs: {len(data)}')"
```

### æ¸…ç†ç¼“å­˜

```bash
# æ¸…ç†Pythonç¼“å­˜
find . -type d -name __pycache__ -exec rm -rf {} +

# æ¸…ç†GPUç¼“å­˜ï¼ˆPythonå†…ï¼‰
python -c "import torch; torch.cuda.empty_cache(); print('GPU cache cleared')"
```

---

## ğŸ“ˆ æ€§èƒ½æµ‹è¯•

### æµ‹è¯•ä¸åŒGPUæ•°é‡

```bash
# æµ‹è¯•å•GPU
python main.py --config config.yaml --categories ç‰©ç†

# æµ‹è¯•2GPU
# (ä¿®æ”¹config_multi_gpu.yaml: device_ids: [0, 1])
python main.py --config config_multi_gpu.yaml --categories ç‰©ç†

# æµ‹è¯•6GPU
# (ä¿®æ”¹config_multi_gpu.yaml: device_ids: [0,1,2,3,4,5])
python main.py --config config_multi_gpu.yaml --categories ç‰©ç†
```

### æµ‹è¯•ä¸åŒBatch Size

```bash
# ä¿®æ”¹ config_multi_gpu.yaml:
# batch_size: 2
python main.py --config config_multi_gpu.yaml --categories ç‰©ç†

# batch_size: 4
python main.py --config config_multi_gpu.yaml --categories ç‰©ç†

# batch_size: 8
python main.py --config config_multi_gpu.yaml --categories ç‰©ç†
```

---

## ğŸ“š æŸ¥çœ‹æ–‡æ¡£

```bash
# æŸ¥çœ‹ä½¿ç”¨æŒ‡å—
cat HOW_TO_RUN.md

# æŸ¥çœ‹æ‰¹æ¬¡åŒæ­¥è¯´æ˜
cat BATCH_SYNC_QUICK_GUIDE.md

# æŸ¥çœ‹æ‰€æœ‰ä¼˜åŒ–æ€»ç»“
cat ALL_OPTIMIZATIONS_COMPLETE.md

# æŸ¥çœ‹é¡¹ç›®README
cat README.md
```

---

## ğŸ¯ å®Œæ•´å·¥ä½œæµ

```bash
# 1. æ¿€æ´»ç¯å¢ƒ
conda activate yx_grpo_rl_post_edit

# 2. è¿›å…¥ç›®å½•
cd /data2/yixuan/image_edit_benchmark

# 3. æ£€æŸ¥GPU
nvidia-smi

# 4. å¿«é€Ÿæµ‹è¯•ï¼ˆ1åˆ†é’Ÿï¼‰
python main.py --config config_multi_gpu.yaml --categories ç‰©ç†

# 5. æŸ¥çœ‹ç»“æœ
cat outputs/evaluation_report_*.md

# 6. å¦‚æœæµ‹è¯•é€šè¿‡ï¼Œè¿è¡Œå®Œæ•´è¯„æµ‹ï¼ˆ5åˆ†é’Ÿï¼‰
python main.py --config config_multi_gpu.yaml

# 7. æŸ¥çœ‹æœ€ç»ˆç»“æœ
ls -lh outputs/
cat outputs/evaluation_report_*.json
```

---

## ğŸ”‘ å…³é”®é…ç½®å‚æ•°

| å‚æ•° | ä½ç½® | æ¨èå€¼ | è¯´æ˜ |
|-----|------|--------|------|
| `device_ids` | diffusion_model.params | `[0,1,2,3,4,5]` | ä½¿ç”¨çš„GPU |
| `enable_batch_sync` | diffusion_model.params | `true` | æ‰¹æ¬¡åŒæ­¥ |
| `use_batch_inference` | reward_model.params | `true` | Batchæ¨ç† |
| `batch_size` | reward_model.params | `4` | æ‰¹å¤„ç†å¤§å° |
| `num_inference_steps` | diffusion_model.params | `50` | å»å™ªæ­¥æ•° |

---

## ğŸ’¡ æœ€ä½³å®è·µ

1. **é¦–æ¬¡è¿è¡Œ**ï¼šå…ˆç”¨å•ç±»åˆ«æµ‹è¯•
   ```bash
   python main.py --config config_multi_gpu.yaml --categories ç‰©ç†
   ```

2. **ç›‘æ§GPU**ï¼šè¿è¡Œæ—¶åœ¨å¦ä¸€ä¸ªç»ˆç«¯ç›‘æ§
   ```bash
   watch -n 1 nvidia-smi
   ```

3. **æŸ¥çœ‹æ—¥å¿—**ï¼šå¦‚æœ‰é—®é¢˜ï¼ŒæŸ¥çœ‹è¯¦ç»†æ—¥å¿—
   ```bash
   tail -f outputs/logs/benchmark_*.log
   ```

4. **ä¿å­˜ç»“æœ**ï¼šè¿è¡Œå®Œåå¤‡ä»½ç»“æœ
   ```bash
   cp -r outputs/ outputs_backup_$(date +%Y%m%d_%H%M%S)/
   ```

---

**æœ€åæ›´æ–°**: 2025-10-23  
**ç‰ˆæœ¬**: v2.1  
**çŠ¶æ€**: âœ… ç”Ÿäº§å°±ç»ª


