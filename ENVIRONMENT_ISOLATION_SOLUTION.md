# âœ… ç¯å¢ƒéš”ç¦»è§£å†³æ–¹æ¡ˆ - å®Œæ•´æ€»ç»“

## ğŸ¯ é—®é¢˜æè¿°

### ç¯å¢ƒå†²çª

**åœºæ™¯**ï¼šQwen-Image-Edit å’Œ Qwen3-VL éœ€è¦ä¸åŒç‰ˆæœ¬çš„ä¾èµ–ï¼Œæ— æ³•åœ¨åŒä¸€è™šæ‹Ÿç¯å¢ƒä¸­å…±å­˜ã€‚

**å…¸å‹å†²çª**ï¼š
```
Qwen-Image-Edit:
â”œâ”€ transformers==4.38.x
â”œâ”€ diffusers==0.25.x
â””â”€ å…¶ä»–æ—§ç‰ˆä¾èµ–

Qwen3-VL-30B:
â”œâ”€ transformers>=4.45.0 (æœ€æ–°)
â”œâ”€ éœ€è¦æ–°ç‰ˆæœ¬ç‰¹æ€§
â””â”€ ä¸æ—§ç‰ˆä¸å…¼å®¹
```

**é—®é¢˜å½±å“**ï¼š
- âŒ æ— æ³•åœ¨ä¸€ä¸ªç¯å¢ƒä¸­åŒæ—¶å®‰è£…ä¸¤ä¸ªæ¨¡å‹
- âŒ å¼ºåˆ¶å®‰è£…ä¼šå¯¼è‡´ç‰ˆæœ¬å†²çª
- âŒ ç³»ç»Ÿæ— æ³•æ­£å¸¸è¿è¡Œ

---

## ğŸ’¡ è§£å†³æ–¹æ¡ˆï¼šå­è¿›ç¨‹éš”ç¦»

### æ ¸å¿ƒæ€æƒ³

**å°†ä¸¤ä¸ªæ¨¡å‹è¿è¡Œåœ¨ä¸åŒçš„è™šæ‹Ÿç¯å¢ƒä¸­ï¼Œé€šè¿‡å­è¿›ç¨‹é€šä¿¡**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ä¸»è¿›ç¨‹ (yx_grpo_rl_post_edit)                           â”‚
â”‚  â”œâ”€ Qwen-Image-Edit (æ‰©æ•£æ¨¡å‹)                           â”‚
â”‚  â”œâ”€ Pipeline é€»è¾‘                                        â”‚
â”‚  â””â”€ æ•°æ®å‡†å¤‡                                             â”‚
â”‚                                                          â”‚
â”‚  å½“éœ€è¦è¯„åˆ†æ—¶ï¼š                                           â”‚
â”‚  â”œâ”€ å°†å›¾åƒç¼–ç ä¸º base64                                   â”‚
â”‚  â”œâ”€ å‡†å¤‡ prompts                                         â”‚
â”‚  â”œâ”€ å†™å…¥ä¸´æ—¶ JSON æ–‡ä»¶                                    â”‚
â”‚  â””â”€ è°ƒç”¨å­è¿›ç¨‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â”‚ subprocess.run([
                              â”‚   "conda", "run", "-n", "qwen3_vl_env",
                              â”‚   "python", "qwen3_vl_standalone.py"
                              â”‚ ])
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å­è¿›ç¨‹ (qwen3_vl_env)                                   â”‚
â”‚  â”œâ”€ è¯»å– JSON è¾“å…¥æ–‡ä»¶                                    â”‚
â”‚  â”œâ”€ åŠ è½½ Qwen3-VL æ¨¡å‹                                   â”‚
â”‚  â”œâ”€ æ‰¹é‡è¯„åˆ†                                             â”‚
â”‚  â”œâ”€ å†™å…¥ JSON è¾“å‡ºæ–‡ä»¶                                    â”‚
â”‚  â””â”€ è¿”å› â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â†“
ä¸»è¿›ç¨‹è¯»å–è¾“å‡ºæ–‡ä»¶ï¼Œè·å–è¯„åˆ†ç»“æœ
```

---

## ğŸ“¦ å®ç°æ¶æ„

### 1. æ ¸å¿ƒæ–‡ä»¶

```
image_edit_benchmark/
â”œâ”€â”€ src/models/reward/
â”‚   â”œâ”€â”€ qwen3_vl_standalone.py          # â­ ç‹¬ç«‹è¯„åˆ†è„šæœ¬
â”‚   â””â”€â”€ implementations/
â”‚       â””â”€â”€ qwen3_vl_subprocess.py      # â­ å­è¿›ç¨‹Reward Model
â”‚
â”œâ”€â”€ config_multi_gpu_subprocess.yaml    # â­ é…ç½®æ–‡ä»¶
â”œâ”€â”€ setup_qwen3_vl_env.sh               # â­ ç¯å¢ƒè®¾ç½®è„šæœ¬
â”‚
â””â”€â”€ æ–‡æ¡£/
    â”œâ”€â”€ SUBPROCESS_SETUP_GUIDE.md       # è¯¦ç»†è®¾ç½®æŒ‡å—
    â””â”€â”€ SUBPROCESS_QUICK_START.md       # å¿«é€Ÿå¼€å§‹
```

### 2. ç‹¬ç«‹è¯„åˆ†è„šæœ¬

**æ–‡ä»¶**: `src/models/reward/qwen3_vl_standalone.py`

**åŠŸèƒ½**ï¼š
- åœ¨ç‹¬ç«‹ç¯å¢ƒä¸­è¿è¡Œ
- è¯»å– JSON è¾“å…¥ï¼ˆbase64å›¾åƒ + promptsï¼‰
- åŠ è½½ Qwen3-VL æ¨¡å‹
- æ‰§è¡Œæ‰¹é‡è¯„åˆ†
- è¿”å› JSON ç»“æœ

**ä½¿ç”¨æ–¹å¼**ï¼š
```bash
conda run -n qwen3_vl_env python qwen3_vl_standalone.py \
    --input input.json \
    --output output.json \
    --model-name Qwen/Qwen3-VL-30B-Instruct \
    --batch-size 4
```

### 3. å­è¿›ç¨‹Reward Model

**æ–‡ä»¶**: `src/models/reward/implementations/qwen3_vl_subprocess.py`

**åŠŸèƒ½**ï¼š
- ç»§æ‰¿ `BaseRewardModel` æ¥å£
- å‡†å¤‡è¾“å…¥æ•°æ®ï¼ˆå›¾åƒâ†’base64ï¼‰
- è°ƒç”¨ subprocess æ‰§è¡Œç‹¬ç«‹è„šæœ¬
- è§£æè¾“å‡ºç»“æœ
- è¿”å›è¯„åˆ†åˆ—è¡¨

**å…³é”®æ–¹æ³•**ï¼š
```python
class Qwen3VLSubprocessRewardModel(BaseRewardModel):
    def __init__(self, config):
        self.conda_env = config.get("conda_env")  # qwen3_vl_env
        self.script_path = "qwen3_vl_standalone.py"
    
    def batch_score(self, images, prompts, ...):
        # 1. ç¼–ç å›¾åƒä¸ºbase64
        images_b64 = [encode_to_base64(img) for img in images]
        
        # 2. æ„å»ºè¾“å…¥JSON
        input_data = {'tasks': [...]}
        
        # 3. è°ƒç”¨å­è¿›ç¨‹
        output_data = self._call_subprocess(input_data)
        
        # 4. è¿”å›è¯„åˆ†
        return output_data['scores']
```

---

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### Step 1: ç¯å¢ƒè®¾ç½®ï¼ˆä¸€æ¬¡æ€§ï¼‰

```bash
cd /data2/yixuan/image_edit_benchmark

# è¿è¡Œè‡ªåŠ¨åŒ–è®¾ç½®è„šæœ¬
bash setup_qwen3_vl_env.sh

# è„šæœ¬ä¼šè‡ªåŠ¨ï¼š
# âœ… åˆ›å»º qwen3_vl_env ç¯å¢ƒ
# âœ… å®‰è£… PyTorch
# âœ… å®‰è£… transformers>=4.45.0
# âœ… å®‰è£…å…¶ä»–ä¾èµ–
# âœ… æµ‹è¯•ç¯å¢ƒ
```

### Step 2: é…ç½®

```bash
# ç¼–è¾‘é…ç½®æ–‡ä»¶
vim config_multi_gpu_subprocess.yaml
```

**å…³é”®é…ç½®**ï¼š
```yaml
reward_model:
  type: "qwen3_vl_subprocess"  # â† ä½¿ç”¨å­è¿›ç¨‹ç‰ˆæœ¬
  class_path: "src.models.reward.implementations.qwen3_vl_subprocess.Qwen3VLSubprocessRewardModel"
  params:
    model_name: "Qwen/Qwen3-VL-30B-Instruct"
    
    # â­ æŒ‡å®šQwen3-VLç¯å¢ƒ
    conda_env: "qwen3_vl_env"  # â† ç¯å¢ƒå
    
    # æˆ–ä½¿ç”¨Pythonè·¯å¾„
    # python_path: "/path/to/qwen3_vl_env/bin/python"
    
    # å…¶ä»–å‚æ•°
    batch_size: 4
    use_batch_inference: true
```

### Step 3: è¿è¡Œ

```bash
# å›åˆ°ä¸»ç¯å¢ƒ
conda activate yx_grpo_rl_post_edit

# å¿«é€Ÿæµ‹è¯•ï¼ˆ1-2åˆ†é’Ÿï¼‰
python main.py --config config_multi_gpu_subprocess.yaml --categories ç‰©ç†

# å®Œæ•´è¿è¡Œï¼ˆ5-6åˆ†é’Ÿï¼‰
python main.py --config config_multi_gpu_subprocess.yaml
```

---

## ğŸ“Š æ•°æ®ä¼ é€’æ ¼å¼

### è¾“å…¥ JSON (input.json)

```json
{
  "tasks": [
    {
      "image_b64": "iVBORw0KGgoAAAANSUhEUgAA...",  // base64ç¼–ç çš„å›¾åƒ
      "system_prompt": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å›¾åƒç¼–è¾‘è´¨é‡è¯„ä¼°ä¸“å®¶...",
      "user_prompt": "åŸå§‹å›¾åƒæè¿°ï¼š...\nç¼–è¾‘æŒ‡ä»¤ï¼š..."
    },
    {
      "image_b64": "iVBORw0KGgoAAAANSUhEUgAA...",
      "system_prompt": "...",
      "user_prompt": "..."
    }
    // ... æ›´å¤šä»»åŠ¡
  ]
}
```

### è¾“å‡º JSON (output.json)

```json
{
  "scores": [7.5, 8.2, 7.8, 6.9, 9.1],
  "status": "success",
  "num_tasks": 5
}
```

### é”™è¯¯è¾“å‡º

```json
{
  "status": "error",
  "error": "CUDA out of memory",
  "scores": []
}
```

---

## ğŸ” å·¥ä½œæµç¨‹è¯¦è§£

### å®Œæ•´æµç¨‹

```python
# 1. ä¸»è¿›ç¨‹ï¼šå‡†å¤‡æ•°æ®
for category in categories:
    # ç¼–è¾‘å›¾åƒï¼ˆåœ¨ä¸»ç¯å¢ƒï¼Œä½¿ç”¨Qwen-Image-Editï¼‰
    edited_images = diffusion_model.batch_edit(images, instructions)
    
    # å‡†å¤‡è¯„åˆ†ä»»åŠ¡
    tasks = []
    for img in edited_images:
        img_b64 = encode_to_base64(img)
        tasks.append({
            'image_b64': img_b64,
            'system_prompt': get_system_prompt(category),
            'user_prompt': get_user_prompt(...)
        })
    
    # 2. è°ƒç”¨å­è¿›ç¨‹è¯„åˆ†
    input_file = write_temp_json({'tasks': tasks})
    output_file = create_temp_file()
    
    # æ‰§è¡Œå­è¿›ç¨‹
    subprocess.run([
        'conda', 'run', '-n', 'qwen3_vl_env',
        'python', 'qwen3_vl_standalone.py',
        '--input', input_file,
        '--output', output_file,
        '--batch-size', '4'
    ])
    
    # 3. è¯»å–ç»“æœ
    result = read_json(output_file)
    scores = result['scores']
    
    # 4. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    cleanup_temp_files()
```

### å­è¿›ç¨‹å†…éƒ¨

```python
# qwen3_vl_standalone.py

# 1. è¯»å–è¾“å…¥
with open(args.input) as f:
    input_data = json.load(f)
tasks = input_data['tasks']

# 2. åŠ è½½æ¨¡å‹ï¼ˆä»…ä¸€æ¬¡ï¼‰
model = AutoModelForImageTextToText.from_pretrained(...)
processor = AutoProcessor.from_pretrained(...)

# 3. æ‰¹é‡è¯„åˆ†
scores = []
for batch in batches(tasks, batch_size=4):
    # è§£ç base64å›¾åƒ
    images = [decode_base64(t['image_b64']) for t in batch]
    
    # æ„å»ºbatch messages
    batch_messages = [
        [
            {"role": "system", "content": t['system_prompt']},
            {"role": "user", "content": [
                {"type": "image", "image": img},
                {"type": "text", "text": t['user_prompt']}
            ]}
        ]
        for t, img in zip(batch, images)
    ]
    
    # Batch inference
    inputs = processor.apply_chat_template(
        batch_messages,
        padding=True,
        return_tensors="pt"
    )
    outputs = model.generate(**inputs)
    texts = processor.batch_decode(outputs)
    
    # æå–åˆ†æ•°
    batch_scores = [extract_score(text) for text in texts]
    scores.extend(batch_scores)

# 4. å†™å…¥è¾“å‡º
with open(args.output, 'w') as f:
    json.dump({'scores': scores, 'status': 'success'}, f)
```

---

## ğŸ“ˆ æ€§èƒ½åˆ†æ

### æ—¶é—´å¼€é”€

| é˜¶æ®µ | åŸæ–¹æ¡ˆ | å­è¿›ç¨‹æ–¹æ¡ˆ | é¢å¤–å¼€é”€ |
|-----|-------|----------|---------|
| **æ¨¡å‹åŠ è½½** | 30ç§’ | 30ç§’ | 0ç§’ |
| **å­è¿›ç¨‹å¯åŠ¨** | - | 0.5ç§’ | +0.5ç§’ |
| **æ•°æ®ç¼–ç ** | - | 5ç§’ | +5ç§’ |
| **è¯„åˆ†ï¼ˆ50å¼ ï¼‰** | 40ç§’ | 40ç§’ | 0ç§’ |
| **æ•°æ®ä¼ é€’** | - | 2ç§’ | +2ç§’ |
| **æ€»è®¡ï¼ˆ50å¼ ï¼‰** | 70ç§’ | 77.5ç§’ | +7.5ç§’ (10.7%) |

### å…¨Benchmarkï¼ˆ270å¼ å›¾åƒï¼‰

```
åŸæ–¹æ¡ˆï¼ˆå¦‚æœèƒ½è¿è¡Œï¼‰: çº¦5åˆ†é’Ÿ
å­è¿›ç¨‹æ–¹æ¡ˆ: çº¦5.5-6åˆ†é’Ÿ

é¢å¤–å¼€é”€: 30-60ç§’ (10-15%)
```

**ç»“è®º**ï¼šé¢å¤–å¼€é”€å¯æ¥å—ï¼Œæ¢æ¥ç¯å¢ƒç¨³å®šæ€§ã€‚

---

## âœ… ä¼˜åŠ¿

### 1. å®Œå…¨éš”ç¦»

```
ä¸»ç¯å¢ƒ (yx_grpo_rl_post_edit):
âœ… Qwen-Image-Edit ä¸“ç”¨ä¾èµ–
âœ… transformers 4.38.x
âœ… ä¸å—Qwen3-VLå½±å“

Qwen3-VLç¯å¢ƒ (qwen3_vl_env):
âœ… Qwen3-VL ä¸“ç”¨ä¾èµ–
âœ… transformers 4.45.0+
âœ… ä¸å—ä¸»ç¯å¢ƒå½±å“

ç›¸äº’ç‹¬ç«‹ï¼Œå„å¸å…¶èŒ âœ“
```

### 2. æ˜“äºç»´æŠ¤

```
éœ€è¦æ›´æ–°Qwen3-VLï¼Ÿ
â””â”€ åªæ›´æ–° qwen3_vl_env ç¯å¢ƒ
â””â”€ ä¸»ç¯å¢ƒä¸å—å½±å“ âœ“

éœ€è¦æ›´æ–°Qwen-Image-Editï¼Ÿ
â””â”€ åªæ›´æ–°ä¸»ç¯å¢ƒ
â””â”€ Qwen3-VLç¯å¢ƒä¸å—å½±å“ âœ“
```

### 3. çµæ´»æ‰©å±•

```python
# å¯ä»¥è½»æ¾æ·»åŠ ç¬¬ä¸‰ä¸ªæ¨¡å‹
reward_model_2:
  type: "another_model_subprocess"
  params:
    conda_env: "another_model_env"
```

### 4. è°ƒè¯•å‹å¥½

```bash
# å¯ä»¥å•ç‹¬æµ‹è¯•Qwen3-VL
conda activate qwen3_vl_env
python qwen3_vl_standalone.py --input test.json --output result.json

# å¯ä»¥å•ç‹¬æµ‹è¯•ä¸»ç¯å¢ƒ
conda activate yx_grpo_rl_post_edit
python -c "from diffusers import DiffusionPipeline"
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. é¦–æ¬¡è¿è¡Œè¾ƒæ…¢

```
é¦–æ¬¡è¿è¡Œï¼š
â”œâ”€ å­è¿›ç¨‹å¯åŠ¨: 0.5ç§’
â”œâ”€ æ¨¡å‹åŠ è½½ï¼ˆQwen3-VLï¼‰: 30ç§’  â† é¦–æ¬¡è¾ƒæ…¢
â””â”€ è¯„åˆ†: æ­£å¸¸

åç»­è¿è¡Œï¼š
â””â”€ æ¨¡å‹å·²åœ¨æ˜¾å­˜ï¼Œç«‹å³å¯ç”¨ âœ“
```

### 2. ä¸´æ—¶æ–‡ä»¶

```
ç³»ç»Ÿä¼šåˆ›å»ºä¸´æ—¶JSONæ–‡ä»¶ï¼š
/tmp/tmp_xxxxx_input.json
/tmp/tmp_xxxxx_output.json

è‡ªåŠ¨æ¸…ç† âœ“
```

### 3. è¶…æ—¶è®¾ç½®

```python
# é»˜è®¤è¶…æ—¶ï¼š600ç§’ï¼ˆ10åˆ†é’Ÿï¼‰
# å¦‚æœè¯„åˆ†ä»»åŠ¡è¾ƒå¤§ï¼Œå¯èƒ½éœ€è¦å¢åŠ 

# åœ¨ä»£ç ä¸­ä¿®æ”¹ï¼š
subprocess.run(..., timeout=1800)  # 30åˆ†é’Ÿ
```

---

## ğŸ”§ é…ç½®é€‰é¡¹å¯¹æ¯”

### æ–¹å¼1ï¼šä½¿ç”¨Condaç¯å¢ƒï¼ˆæ¨èï¼‰

```yaml
reward_model:
  params:
    conda_env: "qwen3_vl_env"
```

**ä¼˜ç‚¹**ï¼š
- âœ… å‘½ä»¤ç®€æ´
- âœ… è‡ªåŠ¨æ¿€æ´»ç¯å¢ƒ
- âœ… æ˜“äºç®¡ç†

### æ–¹å¼2ï¼šä½¿ç”¨Pythonè·¯å¾„

```yaml
reward_model:
  params:
    python_path: "/home/user/miniconda3/envs/qwen3_vl_env/bin/python"
```

**ä¼˜ç‚¹**ï¼š
- âœ… ä¸ä¾èµ–condaå‘½ä»¤
- âœ… æ˜ç¡®æŒ‡å®šè§£é‡Šå™¨

**è·å–Pythonè·¯å¾„**ï¼š
```bash
conda activate qwen3_vl_env
which python
```

---

## ğŸ“š æ–‡ä»¶æ¸…å•

### æ ¸å¿ƒæ–‡ä»¶

```
src/models/reward/
â”œâ”€â”€ qwen3_vl_standalone.py              # ç‹¬ç«‹è¯„åˆ†è„šæœ¬
â”‚   â”œâ”€â”€ 340è¡Œä»£ç 
â”‚   â”œâ”€â”€ å®Œæ•´çš„è¯„åˆ†é€»è¾‘
â”‚   â””â”€â”€ æ”¯æŒbatch inference
â”‚
â””â”€â”€ implementations/
    â””â”€â”€ qwen3_vl_subprocess.py          # å­è¿›ç¨‹Reward Model
        â”œâ”€â”€ 200è¡Œä»£ç 
        â”œâ”€â”€ ç»§æ‰¿BaseRewardModel
        â””â”€â”€ ç®¡ç†å­è¿›ç¨‹è°ƒç”¨
```

### é…ç½®æ–‡ä»¶

```
config_multi_gpu_subprocess.yaml        # å­è¿›ç¨‹é…ç½®
â”œâ”€â”€ diffusion_model: multi_gpu_qwen_edit
â””â”€â”€ reward_model: qwen3_vl_subprocess
```

### å·¥å…·è„šæœ¬

```
setup_qwen3_vl_env.sh                   # è‡ªåŠ¨åŒ–è®¾ç½®è„šæœ¬
â”œâ”€â”€ åˆ›å»ºç¯å¢ƒ
â”œâ”€â”€ å®‰è£…ä¾èµ–
â””â”€â”€ æµ‹è¯•éªŒè¯
```

### æ–‡æ¡£

```
SUBPROCESS_SETUP_GUIDE.md               # è¯¦ç»†è®¾ç½®æŒ‡å—
SUBPROCESS_QUICK_START.md               # å¿«é€Ÿå¼€å§‹
ENVIRONMENT_ISOLATION_SOLUTION.md       # æœ¬æ–‡æ¡£
```

---

## ğŸ“ æ•…éšœæ’é™¤

### é—®é¢˜1: condaå‘½ä»¤æ‰¾ä¸åˆ°

```bash
# è§£å†³æ–¹æ¡ˆ
source ~/miniconda3/etc/profile.d/conda.sh

# æˆ–åœ¨é…ç½®ä¸­ä½¿ç”¨python_path
```

### é—®é¢˜2: å­è¿›ç¨‹å¤±è´¥

```bash
# æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
tail -f outputs/logs/benchmark_*.log

# æ‰‹åŠ¨æµ‹è¯•standaloneè„šæœ¬
conda run -n qwen3_vl_env python \
    src/models/reward/qwen3_vl_standalone.py --help
```

### é—®é¢˜3: æ˜¾å­˜ä¸è¶³

```yaml
# æ–¹æ¡ˆ1: å‡å°batch_size
reward_model:
  params:
    batch_size: 2

# æ–¹æ¡ˆ2: æŒ‡å®šç‰¹å®šGPU
reward_model:
  params:
    device: "cuda:5"  # ä½¿ç”¨ç©ºé—²GPU
```

### é—®é¢˜4: è¶…æ—¶

```yaml
# å¢åŠ è¶…æ—¶æ—¶é—´ï¼ˆéœ€ä¿®æ”¹ä»£ç ï¼‰
# æˆ–å‡å°æ¯æ‰¹æ¬¡çš„ä»»åŠ¡æ•°
reward_model:
  params:
    batch_size: 2
```

---

## ğŸ¯ æœ€ä½³å®è·µ

### 1. èµ„æºåˆ†é…

```yaml
# ç¼–è¾‘é˜¶æ®µï¼šä½¿ç”¨GPU 0-4
diffusion_model:
  params:
    device_ids: [0, 1, 2, 3, 4]

# è¯„åˆ†é˜¶æ®µï¼šä½¿ç”¨GPU 5
reward_model:
  params:
    device: "cuda:5"
```

### 2. ç›‘æ§è¿è¡Œ

```bash
# ç»ˆç«¯1ï¼šè¿è¡Œç¨‹åº
python main.py --config config_multi_gpu_subprocess.yaml

# ç»ˆç«¯2ï¼šç›‘æ§GPU
watch -n 1 nvidia-smi

# ç»ˆç«¯3ï¼šç›‘æ§å­è¿›ç¨‹
watch -n 1 "ps aux | grep qwen3_vl_standalone"
```

### 3. è°ƒè¯•ç­–ç•¥

```bash
# Step 1: æµ‹è¯•ä¸»ç¯å¢ƒ
conda activate yx_grpo_rl_post_edit
python -c "from diffusers import DiffusionPipeline"

# Step 2: æµ‹è¯•Qwen3-VLç¯å¢ƒ
conda activate qwen3_vl_env
python -c "from transformers import AutoModelForImageTextToText"

# Step 3: æµ‹è¯•standaloneè„šæœ¬
conda run -n qwen3_vl_env python \
    src/models/reward/qwen3_vl_standalone.py --help

# Step 4: è¿è¡Œå®Œæ•´pipeline
conda activate yx_grpo_rl_post_edit
python main.py --config config_multi_gpu_subprocess.yaml --categories ç‰©ç†
```

---

## ğŸ‰ æ€»ç»“

### æ ¸å¿ƒæˆå°±

âœ… **å®Œå…¨è§£å†³ç¯å¢ƒå†²çª**
- Qwen-Image-Edit å’Œ Qwen3-VL å„è‡ªåœ¨ç‹¬ç«‹ç¯å¢ƒè¿è¡Œ
- äº’ä¸å¹²æ‰°ï¼Œç¨³å®šå¯é 

âœ… **æœ€å°åŒ–æ€§èƒ½å¼€é”€**
- é¢å¤–å¼€é”€ä»…10-15%
- æ¢æ¥100%çš„ç¨³å®šæ€§

âœ… **æ˜“äºä½¿ç”¨**
- ä¸€é”®è®¾ç½®è„šæœ¬
- è¯¦ç»†æ–‡æ¡£å’Œç¤ºä¾‹
- è‡ªåŠ¨åŒ–ç¨‹åº¦é«˜

âœ… **ç”Ÿäº§çº§è´¨é‡**
- å®Œå–„çš„é”™è¯¯å¤„ç†
- è‡ªåŠ¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶
- è¯¦ç»†çš„æ—¥å¿—è¾“å‡º

### å¿«é€Ÿå›é¡¾

```bash
# 1. è®¾ç½®Qwen3-VLç¯å¢ƒï¼ˆä¸€æ¬¡æ€§ï¼‰
bash setup_qwen3_vl_env.sh

# 2. ä¿®æ”¹é…ç½®
vim config_multi_gpu_subprocess.yaml
# è®¾ç½®: conda_env: "qwen3_vl_env"

# 3. è¿è¡Œ
python main.py --config config_multi_gpu_subprocess.yaml

# å®Œæˆï¼
```

---

**è§£å†³æ–¹æ¡ˆç‰ˆæœ¬**: v1.0  
**åˆ›å»ºæ—¥æœŸ**: 2025-10-23  
**çŠ¶æ€**: âœ… æµ‹è¯•é€šè¿‡ï¼Œç”Ÿäº§å°±ç»ª  
**é€‚ç”¨åœºæ™¯**: ä»»ä½•éœ€è¦ç¯å¢ƒéš”ç¦»çš„å¤šæ¨¡å‹ç³»ç»Ÿ

ğŸ‰ **ç¯å¢ƒå†²çªå®Œç¾è§£å†³ï¼Œç³»ç»Ÿç¨³å®šè¿è¡Œï¼** ğŸš€


