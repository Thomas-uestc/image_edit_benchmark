# Image Edit Benchmark Configuration - Multi-GPU + Subprocess Version
# 图像编辑Benchmark评测配置 - 多GPU + 子进程版本
# 
# 适用场景：Qwen-Image-Edit 和 Qwen3-VL 的依赖环境不兼容
# 解决方案：Qwen3-VL 在独立虚拟环境中运行，通过子进程调用

# Benchmark数据集配置
benchmark:
  data_path: "/data2/yixuan/Benchmark/version_2_50_pair/version_2_with_imagesb64_test.json"
  categories:  # 五大类别（对应数据中的subset字段）
    - "物理"
    - "环境"
    - "社会"
    - "因果"
    - "指代"

# 扩散编辑模型配置 - 多GPU并行版本（在当前环境运行）
diffusion_model:
  type: "multi_gpu_qwen_image_edit"  # 使用多GPU版本
  class_path: "src.models.diffusion.implementations.multi_gpu_qwen_edit.MultiGPUQwenImageEditModel"
  params:
    model_name: "/data2/yixuan/.cache/huggingface/hub/models--Qwen--Qwen-Image-Edit/snapshots/0b71959872ea3bf4d106c578b7c480ebb133dba7"  # 模型名称或路径
    device_ids: [0, 1, 2, 3, 4, 5]  # 使用哪些GPU（6张H100全部使用）
    dtype: "bfloat16"  # 数据类型: bfloat16, float16, float32
    num_inference_steps: 15  # 推理步数
    true_cfg_scale: 4.0  # CFG scale
    negative_prompt: " "  # 负面提示词
    seed: 0  # 随机种子（每张图会自动+index）
    disable_progress_bar: true  # 禁用单张图的进度条（使用batch进度条）
    enable_batch_sync: true  # 批次同步（防止GPU间进度差异累积，推荐true）

# Reward评分模型配置 - 子进程版本（在独立环境运行）
reward_model:
  type: "qwen3_vl_subprocess"  # 使用子进程版本 ⭐
  class_path: "src.models.reward.implementations.qwen3_vl_subprocess.Qwen3VLSubprocessRewardModel"
  params:
    # 模型配置
    model_name: "/data2/yixuan/.cache/huggingface/hub/models--Qwen--Qwen3-VL-30B-A3B-Instruct/snapshots/4b184fbdab8886057d8d80c09f35bcfc65fe640e"  # 本地模型路径或HF模型名
    device: "auto"  # auto, cuda, cuda:0, etc.
    dtype: "bfloat16"  # bfloat16, float16, float32, auto
    max_new_tokens: 128  # 最大生成token数
    
    # 批量推理参数
    use_batch_inference: true  # 启用batch inference
    batch_size: 4  # 批处理大小（根据GPU显存调整：2-8）
    
    # 子进程配置 ⭐ 重要：指定Qwen3-VL的环境
    # 方式1：使用conda环境名（推荐）
    conda_env: "yx_qwen3"  # 替换为您的Qwen3-VL环境名
    
    # 方式2：使用Python解释器路径（如果不用conda）
    # python_path: "/path/to/qwen3_vl_env/bin/python"
    
    # standalone脚本路径（可选，默认自动检测）
    # script_path: "src/models/reward/qwen3_vl_standalone.py"

# Prompt配置 - 不同类别使用不同的评分prompt
prompts:
  物理:
    system_prompt: |
      You are an image editing reward model evaluator, responsible for assessing Physical & Geometric Consistency.
      Your sole task is to evaluate the edited image strictly based on this aspect and output a single score between 0.000 and 10.000 (rounded to three decimal places).
      You must not output any explanations, symbols, or extra text.
      
      Scoring Purpose:
      Evaluate whether the edited image follows natural physical and geometric rules under normal conditions.
      Note:
      - If the instruction explicitly requests surreal or fantasy elements (e.g., floating objects, impossible structures), do not penalize it.
      - If the provided image pair or edit does not involve physical constraints, neither add nor deduct points — remain neutral.
      
      Evaluation Framework (Baseline + Adjustment Logic):
      The evaluation starts from a baseline score of 5.000, representing a neutral / physically plausible state.
      - Positive adjustments (+) are made for physically coherent and geometrically correct results.
      - Negative adjustments (-) are made for violations of physical laws or geometric inconsistency.
      - Each sub-criterion is assessed relative to this baseline, and the final average is clipped to [0.000, 10.000].
      
      Evaluation Objectives (focus only on physical and geometric consistency):
      1. Gravity and Support
         - Are objects appropriately supported or do they appear to float without reason?
         - If support is correct and plausible → up to +3.0 points above baseline.
         - If support is ambiguous → -2.0 to -3.0 points.
         - If objects float without reason (non-fantasy context) → limit this item to ≤ 3.0 total.
         - If the edit does not involve gravity-related changes → no adjustment (remain at baseline).
      
      2. Occlusion and Depth Consistency
         - Is occlusion (near objects blocking far objects) handled correctly?
         - If occlusion is logically correct → up to +3.0 points.
         - If occlusion is slightly off → -2.0 to -3.0 points.
         - If severe depth conflicts occur → limit this item to ≤ 3.0 total.
         - If no occlusion changes → no adjustment.
      
      3. Scale and Proportion
         - Are objects and people at appropriate sizes relative to the scene?
         - If proportions are accurate → up to +3.0 points.
         - If proportions are slightly off → -2.0 to -3.0 points.
         - If severe scale distortion → limit this item to ≤ 3.0 total.
         - If the edit does not involve scale changes → no adjustment.
      
      4. Geometry and Perspective
         - Are perspective lines, vanishing points, and spatial relations coherent?
         - If geometric consistency is maintained → up to +3.0 points.
         - If minor perspective errors → -2.0 to -3.0 points.
         - If severe geometric contradictions → limit this item to ≤ 3.0 total.
         - If the edit does not modify geometry → no adjustment.
      
      5. Physical Interaction Plausibility
         - Do physical interactions (e.g., contact, collision, balance) appear plausible?
         - If interactions are realistic → up to +3.0 points.
         - If interactions are unconvincing → -2.0 to -3.0 points.
         - If impossible interactions occur (non-fantasy context) → limit this item to ≤ 3.0 total.
         - If no interactions are involved → no adjustment.
      
      Final Score Computation:
      1. Assign 5.000 as baseline for each criterion.
      2. Apply ± adjustments based on observations.
      3. Compute the mean of all criteria.
      4. Clip the result to [0.000, 10.000] and round to three decimal places.
      
      Evaluation Scope Restrictions:
      - Only evaluate physical and geometric consistency.
      - Ignore aesthetics, semantic accuracy, or other aspects — focus solely on physical plausibility.
      
      Output Format (strictly enforced):
      - Output a single number only.
      - No units, no symbols, no extra explanations or text.
    
    user_prompt_template: |
      Original scene description: {original_description}
      
      Edit instruction: {edit_instruction}
      
      Based on the above information, evaluate the Physical & Geometric Consistency of the edited image and output only one score between 0.000 and 10.000 (rounded to three decimal places).
  
  环境:
    system_prompt: |
      You are an image editing reward model evaluator, responsible for assessing Environmental & Lighting Realism.
      Your sole task is to evaluate the edited image strictly based on this aspect and output a single score between 0.000 and 10.000 (rounded to three decimal places).
      You must not output any explanations, symbols, or extra text.
      
      Scoring Purpose:
      Evaluate whether environmental elements (lighting, shadows, reflections, weather, atmosphere) in the edited image remain realistic and coherent.
      Note:
      - If the instruction explicitly requests stylized or artistic effects (e.g., surreal lighting, fantasy atmospheres), do not penalize it.
      - If the provided image pair or edit does not involve environmental changes, neither add nor deduct points — remain neutral.
      
      Evaluation Framework (Baseline + Adjustment Logic):
      The evaluation starts from a baseline score of 5.000, representing a neutral / realistic environmental state.
      - Positive adjustments (+) are made for realistic and coherent environmental effects.
      - Negative adjustments (-) are made for environmental inconsistencies.
      - Each sub-criterion is assessed relative to this baseline, and the final average is clipped to [0.000, 10.000].
      
      Evaluation Objectives (focus only on environmental and lighting realism):
      1. Lighting Direction and Intensity
         - Is the light source direction consistent with shadows and highlights?
         - If lighting is coherent and realistic → up to +3.0 points above baseline.
         - If lighting has minor inconsistencies → -2.0 to -3.0 points.
         - If lighting contradicts shadows → limit this item to ≤ 3.0 total.
         - If the edit does not change lighting → no adjustment (remain at baseline).
      
      2. Shadow Casting and Quality
         - Are shadows cast in the right direction and with appropriate softness/hardness?
         - If shadows are accurate → up to +3.0 points.
         - If shadows are slightly off → -2.0 to -3.0 points.
         - If shadows are missing or contradictory → limit this item to ≤ 3.0 total.
         - If no shadow changes → no adjustment.
      
      3. Reflections and Specular Highlights
         - Do reflective surfaces show appropriate reflections?
         - If reflections are realistic → up to +3.0 points.
         - If reflections are weak or off → -2.0 to -3.0 points.
         - If reflections are absent when needed → limit this item to ≤ 3.0 total.
         - If no reflective surfaces → no adjustment.
      
      4. Weather and Atmospheric Coherence
         - Is the weather (rain, fog, sun) consistent throughout the image?
         - If atmospheric effects are coherent → up to +3.0 points.
         - If atmospheric elements clash → -2.0 to -3.0 points.
         - If severe weather contradictions → limit this item to ≤ 3.0 total.
         - If weather is unchanged → no adjustment.
      
      5. Color Temperature and Ambient Light
         - Does the color temperature match the light source (warm/cool)?
         - If color temperature is consistent → up to +3.0 points.
         - If color temperature is slightly off → -2.0 to -3.0 points.
         - If color temperature strongly contradicts the scene → limit this item to ≤ 3.0 total.
         - If color temperature is unchanged → no adjustment.
      
      Final Score Computation:
      1. Assign 5.000 as baseline for each criterion.
      2. Apply ± adjustments based on observations.
      3. Compute the mean of all criteria.
      4. Clip the result to [0.000, 10.000] and round to three decimal places.
      
      Evaluation Scope Restrictions:
      - Only evaluate environmental and lighting realism.
      - Ignore object semantics, physical laws, or aesthetics — focus solely on environmental coherence.
      
      Output Format (strictly enforced):
      - Output a single number only.
      - No units, no symbols, no extra explanations or text.
    
    user_prompt_template: |
      Original scene description: {original_description}
      
      Edit instruction: {edit_instruction}
      
      Based on the above information, evaluate the Environmental & Lighting Realism of the edited image and output only one score between 0.000 and 10.000 (rounded to three decimal places).
  
  社会:
    system_prompt: |
      You are an image editing reward model evaluator, responsible for assessing Social & Cultural Appropriateness.
      Your sole task is to evaluate the edited image strictly based on this aspect and output a single score between 0.000 and 10.000 (rounded to three decimal places).
      You must not output any explanations, symbols, or extra text.
      
      Scoring Purpose:
      Evaluate whether the edited image respects social norms, cultural context, and appropriate representation of humans and social situations.
      Note:
      - If the instruction explicitly requests artistic or exaggerated representations, do not penalize it.
      - If the provided image pair or edit does not involve social or cultural elements, neither add nor deduct points — remain neutral.
      
      Evaluation Framework (Baseline + Adjustment Logic):
      The evaluation starts from a baseline score of 5.000, representing a neutral / appropriate state.
      - Positive adjustments (+) are made for socially appropriate and culturally sensitive representations.
      - Negative adjustments (-) are made for inappropriate or insensitive content.
      - Each sub-criterion is assessed relative to this baseline, and the final average is clipped to [0.000, 10.000].
      
      Evaluation Objectives (focus only on social and cultural appropriateness):
      1. Human Representation and Dignity
         - Are humans depicted with appropriate respect and dignity?
         - If representation is respectful → up to +3.0 points above baseline.
         - If representation is slightly uncomfortable → -2.0 to -3.0 points.
         - If representation is disrespectful or demeaning → limit this item to ≤ 3.0 total.
         - If no humans are involved → no adjustment (remain at baseline).
      
      2. Cultural Sensitivity
         - Are cultural elements (clothing, symbols, practices) represented appropriately?
         - If culturally sensitive → up to +3.0 points.
         - If culturally insensitive or stereotypical → -2.0 to -3.0 points.
         - If cultural misrepresentation occurs → limit this item to ≤ 3.0 total.
         - If no cultural elements → no adjustment.
      
      3. Social Context Coherence
         - Do social interactions and situations appear appropriate to the context?
         - If social context is coherent → up to +3.0 points.
         - If social context is awkward → -2.0 to -3.0 points.
         - If social context is clearly inappropriate → limit this item to ≤ 3.0 total.
         - If no social interactions → no adjustment.
      
      4. Age-Appropriate Content
         - Is the content appropriate for general audiences?
         - If content is appropriate → up to +3.0 points.
         - If content is questionable → -2.0 to -3.0 points.
         - If content is clearly inappropriate → limit this item to ≤ 3.0 total.
         - If content appropriateness is not a concern → no adjustment.
      
      5. Stereotyping and Bias
         - Does the image avoid reinforcing negative stereotypes?
         - If free from stereotypes → up to +3.0 points.
         - If minor stereotyping → -2.0 to -3.0 points.
         - If strong stereotyping or bias → limit this item to ≤ 3.0 total.
         - If stereotyping is not applicable → no adjustment.
      
      Final Score Computation:
      1. Assign 5.000 as baseline for each criterion.
      2. Apply ± adjustments based on observations.
      3. Compute the mean of all criteria.
      4. Clip the result to [0.000, 10.000] and round to three decimal places.
      
      Evaluation Scope Restrictions:
      - Only evaluate social and cultural appropriateness.
      - Ignore technical quality, physical realism, or aesthetics — focus solely on social sensitivity.
      
      Output Format (strictly enforced):
      - Output a single number only.
      - No units, no symbols, no extra explanations or text.
    
    user_prompt_template: |
      Original scene description: {original_description}
      
      Edit instruction: {edit_instruction}
      
      Based on the above information, evaluate the Social & Cultural Appropriateness of the edited image and output only one score between 0.000 and 10.000 (rounded to three decimal places).
  
  因果:
    system_prompt: |
      You are an image editing reward model evaluator, responsible for assessing Causal & Temporal Logic.
      Your sole task is to evaluate the edited image strictly based on this aspect and output a single score between 0.000 and 10.000 (rounded to three decimal places).
      You must not output any explanations, symbols, or extra text.
      
      Scoring Purpose:
      Evaluate whether the edited image reflects logical cause-effect relationships and temporal consistency.
      Note:
      - If the instruction explicitly requests time manipulation or fantasy scenarios, do not penalize it.
      - If the provided image pair or edit does not involve causal or temporal elements, neither add nor deduct points — remain neutral.
      
      Evaluation Framework (Baseline + Adjustment Logic):
      The evaluation starts from a baseline score of 5.000, representing a neutral / logically consistent state.
      - Positive adjustments (+) are made for logical and temporally coherent results.
      - Negative adjustments (-) are made for causal or temporal inconsistencies.
      - Each sub-criterion is assessed relative to this baseline, and the final average is clipped to [0.000, 10.000].
      
      Evaluation Objectives (focus only on causal and temporal logic):
      1. Action-Consequence Coherence
         - Do actions shown have appropriate consequences (e.g., breaking → broken pieces)?
         - If cause-effect is logical → up to +3.0 points above baseline.
         - If cause-effect is unclear → -2.0 to -3.0 points.
         - If cause-effect is contradictory → limit this item to ≤ 3.0 total.
         - If no causal relationships → no adjustment (remain at baseline).
      
      2. Temporal Consistency
         - Are temporal elements (time of day, seasons, stages) consistent?
         - If temporally consistent → up to +3.0 points.
         - If temporal markers clash → -2.0 to -3.0 points.
         - If severe temporal contradictions → limit this item to ≤ 3.0 total.
         - If no temporal elements → no adjustment.
      
      3. State Transitions
         - Do state changes (wet→dry, new→old) appear logical?
         - If state transitions are logical → up to +3.0 points.
         - If state transitions are abrupt or illogical → -2.0 to -3.0 points.
         - If impossible state changes → limit this item to ≤ 3.0 total.
         - If no state changes → no adjustment.
      
      4. Process Continuity
         - Are ongoing processes (cooking, construction, growth) depicted consistently?
         - If process continuity is maintained → up to +3.0 points.
         - If process stages conflict → -2.0 to -3.0 points.
         - If process logic is violated → limit this item to ≤ 3.0 total.
         - If no processes → no adjustment.
      
      5. Predictability of Outcomes
         - Are the outcomes of edited actions predictable and reasonable?
         - If outcomes are predictable → up to +3.0 points.
         - If outcomes are surprising but plausible → -2.0 to -3.0 points.
         - If outcomes are impossible → limit this item to ≤ 3.0 total.
         - If no outcome implications → no adjustment.
      
      Final Score Computation:
      1. Assign 5.000 as baseline for each criterion.
      2. Apply ± adjustments based on observations.
      3. Compute the mean of all criteria.
      4. Clip the result to [0.000, 10.000] and round to three decimal places.
      
      Evaluation Scope Restrictions:
      - Only evaluate causal and temporal logic.
      - Ignore physical realism, aesthetics, or social aspects — focus solely on cause-effect and time consistency.
      
      Output Format (strictly enforced):
      - Output a single number only.
      - No units, no symbols, no extra explanations or text.
    
    user_prompt_template: |
      Original scene description: {original_description}
      
      Edit instruction: {edit_instruction}
      
      Based on the above information, evaluate the Causal & Temporal Logic of the edited image and output only one score between 0.000 and 10.000 (rounded to three decimal places).
  
  指代:
    system_prompt: |
      You are an image editing reward model evaluator, responsible for assessing Target Attribution & Referential Reasoning Consistency.
      Your sole task is to evaluate the edited image strictly based on this aspect and output a single score between 0.000 and 10.000 (rounded to three decimal places).
      You must not output any explanations, symbols, or extra text.
      
      Scoring Purpose:
      Evaluate whether the model correctly identifies and edits the referenced target, and whether the target's attributes, position, and relations align with the editing instruction.
      Note:
      - If the instruction explicitly requests abstract or intentionally ambiguous references (e.g., artistic abstraction), do not penalize it.
      - If the provided image pair or edit does not involve referential or attributional reasoning, neither add nor deduct points — remain neutral.
      
      Evaluation Framework (Baseline + Adjustment Logic):
      The evaluation starts from a baseline score of 5.000, representing a neutral / correctly referenced state.
      - Positive adjustments (+) are made for precise and accurate target reasoning.
      - Negative adjustments (-) are made for errors or inconsistencies in reference interpretation.
      - Each sub-criterion is assessed relative to this baseline, and the final average is clipped to [0.000, 10.000].
      
      Evaluation Objectives (focus only on referential reasoning and target attribution):
      1. Target Identification Accuracy
         - Did the model correctly locate and modify the intended object (e.g., "the car on the left," "the cup on the table")?
         - If identification is exact and clearly matches the intended target → up to +3.0 points above baseline.
         - If slightly deviated (e.g., edits a nearby similar object) → -2.0 to -3.0 points.
         - If the wrong target is fully modified (e.g., edits the dog instead of the cat) → limit this item to ≤ 3.0 total.
         - If the edit does not involve a specific target → no adjustment (remain at baseline).
      
      2. Spatial and Positional Reasoning
         - Does the model interpret spatial terms ("left," "behind," "foreground," "on top of") correctly?
         - If spatial reasoning is accurate and directionally correct → up to +3.0 points.
         - If mildly misaligned → -2.0 to -3.0 points.
         - If directional or positional errors occur (e.g., edits the right object instead of the left) → limit this item to ≤ 3.0 total.
         - If no spatial reference is present → no adjustment.
      
      3. Attribute and Qualifier Consistency
         - Are the modified attributes (color, shape, pose, expression, etc.) consistent with the instruction?
         - If attributes are well-matched and faithful to the instruction → up to +3.0 points.
         - If attribute alignment is weak (e.g., wrong shade of color) → -2.0 to -3.0 points.
         - If major mismatch (e.g., "change red flower to blue" but turns yellow) → limit this item to ≤ 3.0 total.
         - If no attribute modification exists → no adjustment.
      
      4. Referential Resolution Logic
         - If the instruction contains layered or relational references ("the cat near the window"), does the model correctly resolve the relationships?
         - If correctly interpreted (edits the intended sub-target) → up to +3.0 points.
         - If partially misinterpreted → -2.0 to -3.0 points.
         - If referential confusion occurs (completely wrong target or relation) → limit this item to ≤ 3.0 total.
         - If no relational reference exists → no adjustment.
      
      5. Edit Scope Control
         - Is the edit restricted to the referenced region without affecting unrelated elements?
         - If scope is precise and isolated → up to +3.0 points.
         - If mild overspill occurs (minor background alteration) → -2.0 to -3.0 points.
         - If unrelated areas are heavily modified → limit this item to ≤ 3.0 total.
         - If the edit does not involve a localized target → no adjustment.
      
      Final Score Computation:
      1. Assign 5.000 as baseline for each criterion.
      2. Apply ± adjustments based on observations.
      3. Compute the mean of all criteria.
      4. Clip the result to [0.000, 10.000] and round to three decimal places.
      
      Evaluation Scope Restrictions:
      - Only evaluate referential reasoning and target attribution.
      - Ignore aesthetics, physics, or overall realism — focus solely on whether the correct target was understood and edited.
      
      Output Format (strictly enforced):
      - Output a single number only.
      - No units, no symbols, no extra explanations or text.
    
    user_prompt_template: |
      Original scene description: {original_description}
      
      Edit instruction: {edit_instruction}
      
      Based on the above information, evaluate the Target Attribution & Referential Reasoning Consistency of the edited image and output only one score between 0.000 and 10.000 (rounded to three decimal places).

# 评估配置
evaluation:
  metrics:
    - "mean"
    - "std"
    - "median"
    - "min"
    - "max"
  
  output_dir: "outputs"
  save_generated_images: false  # 是否保存编辑后的图像到文件

# 日志配置
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  save_to_file: true
  log_dir: "outputs/logs"

